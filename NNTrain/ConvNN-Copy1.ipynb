{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thomas/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "(2, 4)\n",
      "[['X11' 'NN11' 'NNN11' 'X12' 'NN12' 'NNN12' 'X13' 'NN13' 'NNN13' 'X14'\n",
      "  'NN14' 'NNN14']\n",
      " ['X21' 'NN21' 'NNN21' 'X22' 'NN22' 'NNN22' 'X23' 'NN23' 'NNN23' 'X24'\n",
      "  'NN24' 'NNN24']]\n",
      "[['X11' 'NN11' 'NNN11']\n",
      " ['X12' 'NN12' 'NNN12']\n",
      " ['X13' 'NN13' 'NNN13']\n",
      " ['X14' 'NN14' 'NNN14']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "tf.disable_v2_behavior()\n",
    "print(np.array([['X11','X12','X13','X14'],['X21','X22','X23','X24']]).shape)\n",
    "posdata = np.stack(([['X11','X12','X13','X14'],['X21','X22','X23','X24']],[['NN11','NN12','NN13','NN14'],['NN21','NN22','NN23','NN24']],[['NNN11','NNN12','NNN13','NNN14'],['NNN21','NNN22','NNN23','NNN24']]),axis=2)\n",
    "   \n",
    "posdata=np.reshape(posdata,(2,4*3))\n",
    "print(posdata)\n",
    "posdata=np.reshape(posdata[0],(4,3))\n",
    "print(posdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name,maxrow):\n",
    "    print(\"read data from \\\"\",file_name,\"\\\"\")\n",
    "    \n",
    "    xdata=np.loadtxt(file_name,max_rows=maxrow)\n",
    "    L=(xdata.shape[1]-3)//9\n",
    "    print(L)\n",
    "    ydata=xdata[:,1]\n",
    "    dxdata=xdata[:,xdata.shape[1]-1]\n",
    "    \n",
    "    posdata=xdata[:,2+4*L:2+5*L]\n",
    "    NNdata=np.stack((xdata[:,2+L:2+2*L],xdata[:,2+3*L:2+4*L],xdata[:,2+5*L:2+6*L],xdata[:,2+7*L:2+8*L]),axis=2)\n",
    "    NNNdata=np.stack((xdata[:,2:2+L],xdata[:,2+2*L:2+3*L],xdata[:,2+6*L:2+7*L],xdata[:,2+8*L:2+9*L]),axis=2)\n",
    "    NNdata=np.mean(NNdata,axis=2)\n",
    "    NNNdata=np.mean(NNNdata,axis=2)\n",
    "    \n",
    "    averagex=np.mean(xdata[:,2:xdata.shape[1]-1])\n",
    "    print(averagex)\n",
    "    gdata_append=0.25*(posdata+np.outer(dxdata,np.ones(L))-averagex)**4-averagex**2/2.0*(posdata+np.outer(dxdata,np.ones(L))-averagex)**2-0.25*(posdata-averagex)**4+averagex**2/2.0*(posdata-averagex)**2\n",
    "    print(np.outer(dxdata,np.ones(L)).shape)\n",
    "    gdata_append=np.mean(gdata_append,axis=1)\n",
    "    zdata_append=np.sum((posdata+np.outer(dxdata,np.ones(L)))**2-posdata**2,axis=1)\n",
    "    print(posdata.shape)\n",
    "    posdata = np.stack((posdata,NNdata,NNNdata),axis=2)\n",
    "   \n",
    "    posdata=np.reshape(posdata,(maxrow,L*3))\n",
    "    \n",
    "    return posdata, dxdata, ydata, zdata_append, gdata_append\n",
    "\n",
    "\n",
    "def load_data2(file_name,maxrow):\n",
    "    print(\"read data from \\\"\",file_name,\"\\\"\")\n",
    "    \n",
    "    xdata=np.loadtxt(file_name,max_rows=maxrow)\n",
    "    L=(xdata.shape[1]-3)//9\n",
    "    print(L)\n",
    "    ydata=xdata[:,1]\n",
    "    dxdata=xdata[:,xdata.shape[1]-1]\n",
    "    \n",
    "    posdata=xdata[:,2+8*L:2+9*L]\n",
    "    NNdata=np.stack((xdata[:,2+L:2+2*L],xdata[:,2+3*L:2+4*L],xdata[:,2+4*L:2+5*L],xdata[:,2+6*L:2+7*L]),axis=2)\n",
    "    NNNdata=np.stack((xdata[:,2:2+L],xdata[:,2+2*L:2+3*L],xdata[:,2+5*L:2+6*L],xdata[:,2+7*L:2+8*L]),axis=2)\n",
    "    NNdata=np.mean(NNdata,axis=2)\n",
    "    NNNdata=np.mean(NNNdata,axis=2)\n",
    "    \n",
    "    averagex=np.mean(xdata[:,2:xdata.shape[1]-1])\n",
    "    print(averagex)\n",
    "    gdata_append=0.25*(posdata+np.outer(dxdata,np.ones(L))-averagex)**4-averagex**2/2.0*(posdata+np.outer(dxdata,np.ones(L))-averagex)**2-0.25*(posdata-averagex)**4+averagex**2/2.0*(posdata-averagex)**2\n",
    "    print(np.outer(dxdata,np.ones(L)).shape)\n",
    "    gdata_append=np.mean(gdata_append,axis=1)\n",
    "    zdata_append=np.sum((posdata+np.outer(dxdata,np.ones(L)))**2-posdata**2,axis=1)\n",
    "    print(posdata.shape)\n",
    "    posdata = np.stack((posdata,NNdata,NNNdata),axis=2)\n",
    "   \n",
    "    posdata=np.reshape(posdata,(maxrow,L*3))\n",
    "    \n",
    "    return posdata, dxdata, ydata, zdata_append, gdata_append\n",
    "\n",
    "\n",
    "\n",
    "def scaled_data(xdata):\n",
    "    xdata_mean=np.mean(xdata,axis=0)\n",
    "    xdata_std=np.std(xdata,axis=0)\n",
    "    xdata_scaled= (xdata-xdata_mean)/xdata_std\n",
    "    return xdata_scaled, xdata_mean, xdata_std\n",
    "\n",
    "\n",
    "def get_next_batch(x,y,start,end):\n",
    "    x_batch=x[start:end,0:x.shape[1]-3]\n",
    "    dx_batch=x[start:end,x.shape[1]-3]\n",
    "    z_batch=x[start:end,x.shape[1]-2]\n",
    "    g_batch=x[start:end,x.shape[1]-1]\n",
    "    y_batch=y[start:end]\n",
    "    return x_batch, dx_batch, z_batch, g_batch, y_batch\n",
    "\n",
    "\n",
    "def weight_variable(name, shape):\n",
    "    initer=tf.truncated_normal_initializer(stddev=0.02)\n",
    "    return tf.get_variable('W_'+name, dtype=tf.float32,shape=shape,initializer=initer)\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    initial=tf.constant(0.0,shape=shape,dtype=tf.float32)\n",
    "    return tf.get_variable('b_'+name,dtype=tf.float32,initializer=initial)\n",
    "\n",
    "def create_new_conv_layer(input_data, deltax, num_filters, filter_shape, name):\n",
    "    # setup the filter input shape for tf.nn.conv_2d\n",
    "    conv_filt_shape = [filter_shape[0], filter_shape[1], 1, num_filters]\n",
    "\n",
    "    # initialise weights and bias for the filter\n",
    "    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),\n",
    "                                      name=name+'_W')\n",
    "    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n",
    "\n",
    "    # setup the convolutional layer operation\n",
    "    out_layer = tf.nn.conv2d(input_data, weights, [1, 3, 1, 1],padding='VALID')\n",
    "\n",
    "    # add the bias\n",
    "    out_layer += bias\n",
    "    \n",
    "    # add the theta term\n",
    "    in_dim=dx.get_shape()[1]\n",
    "    theta = tf.Variable(tf.truncated_normal([in_dim,num_filters]), name=name+'_theta')\n",
    "    out_layer +=tf.tensordot(tf.tensordot(tf.squeeze(dx),tf.ones([12],tf.float32),axes=0),theta,axes=0)\n",
    "\n",
    "    # apply a sigmoid non-linear activation\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "\n",
    "    \n",
    "    return out_layer, weights, bias, theta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fc_layer(x,num_units,name,activation):\n",
    "    in_dim=x.get_shape()[1]\n",
    "    W=weight_variable(name,shape=[in_dim,num_units])\n",
    "    b=bias_variable(name,[num_units])\n",
    "    layer=tf.matmul(x,W)\n",
    "    layer+=b\n",
    "    if activation=='softplus':\n",
    "        layer=tf.nn.softplus(layer)\n",
    "    elif activation=='sigmoid':\n",
    "        layer=tf.nn.sigmoid(layer)\n",
    "    return layer, W, b\n",
    "\n",
    "def fc_layer_final(x,g,z,num_units,name):\n",
    "    in_dim=x.get_shape()[1]\n",
    "    W1=weight_variable(name,shape=[in_dim,num_units])\n",
    "    W2g=weight_variable(name+'g',shape=[1,num_units])\n",
    "    W3z=weight_variable(name+'x',shape=[1,num_units])\n",
    "    b=bias_variable(name,[num_units])\n",
    "    \n",
    "    layer=tf.matmul(x,W1)+tf.matmul(g,W2g)+tf.matmul(z,W3z)\n",
    "\n",
    "    layer+=b\n",
    "    return layer, W1, W2g, W3z, b\n",
    "\n",
    "def save_data(file_name,name,x,matrix):\n",
    "    out_file=open(file_name,'a')\n",
    "    if matrix:\n",
    "        out_file.write(\"%30s: [  %4d  ,  %4d  ]\\n\"%(name,x.shape[0], x.shape[1]))\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                out_file.write(\"%10.6f    \" %(x[i,j]))\n",
    "            out_file.write(\"\\n\")\n",
    "    else:\n",
    "        out_file.write(\"%s: [  %4d  ]\\n\"%(name,x.shape[0]))\n",
    "        for i in range(x.shape[0]):\n",
    "            out_file.write(\"%10.6f    \"%(x[i]))\n",
    "        out_file.write(\"\\n\")\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "#file_name=\"./traindata/build/globaltrain.dat\"\n",
    "file_name=\"./Desktop/block_train0003.dat\"\n",
    "\n",
    "maxrow=100000\n",
    "\n",
    "# set hyper parameters\n",
    "epochs=1000\n",
    "batch_size=200\n",
    "display_freq=50\n",
    "learning_rate=0.001\n",
    "L2_regularization=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from \" ./Desktop/block_train0003.dat \"\n",
      "41\n",
      "3.998107016961392\n",
      "(100000, 41)\n",
      "(100000, 41)\n",
      "Size of:\n",
      "x_train:\t(67000, 126)\n",
      "y_train:\t(67000,)\n",
      "x_test:\t(33000, 126)\n",
      "y_test:\t(33000,)\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "#xdata, dxdata, ydata, zdata_append, gdata_append=load_data(file_name,maxrow)\n",
    "xdata, dxdata, ydata, zdata_append, gdata_append=load_data2(file_name,maxrow)\n",
    "\n",
    "# scaled data\n",
    "xdata_scaled,        xdata_mean,        xdata_std        = scaled_data(xdata)\n",
    "zdata_append_scaled, zdata_append_mean, zdata_append_std = scaled_data(zdata_append)\n",
    "gdata_append_scaled, gdata_append_mean, gdata_append_std = scaled_data(gdata_append)\n",
    "dxdata_scaled,       dxdata_mean,       dxdata_std       = scaled_data(dxdata)\n",
    "xdata_combined=np.concatenate((xdata_scaled,np.array([dxdata_scaled]).T,np.array([zdata_append_scaled]).T,np.array([gdata_append_scaled]).T),axis=1)\n",
    "\n",
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(xdata_combined, ydata, test_size=0.33, random_state=42)\n",
    "L = (x_train.shape[1]-3)//3\n",
    "print(\"Size of:\")\n",
    "print('x_train:\\t{}'.format(x_train.shape))\n",
    "print('y_train:\\t{}'.format(y_train.shape))\n",
    "print('x_test:\\t{}'.format(x_test.shape))\n",
    "print('y_test:\\t{}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178.39236700513172\n"
     ]
    }
   ],
   "source": [
    "print(gdata_append_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thomas/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:4022: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n"
     ]
    }
   ],
   "source": [
    "#create placeholders\n",
    "x = tf.placeholder(tf.float32,shape=[None, x_train.shape[1]-3],name='X')\n",
    "x_shaped = tf.reshape(x,[-1,L,3,1])\n",
    "dx = tf.placeholder(tf.float32,shape=[None, 1] ,name='dX')\n",
    "g = tf.placeholder(tf.float32,shape=[None, 1] ,name='g')\n",
    "z = tf.placeholder(tf.float32,shape=[None, 1] ,name='z')\n",
    "y = tf.placeholder(tf.float32,shape=[None,1] ,name='Y')\n",
    "\n",
    "#define the network\n",
    "convout, Wconv, bconv, thetaconv = create_new_conv_layer(x_shaped, dx, 10, [8,3], name=\"convlayer\")\n",
    "flattened = tf.reshape(convout, [-1, 10*((L-8)//3+1)])\n",
    "fc1, W1, b1 = fc_layer(flattened, 20 , 'FC1' , 'sigmoid')\n",
    "\n",
    "output, W2, W2g, W2z, b2 = fc_layer_final(fc1,g,z,1,'FC2')\n",
    "\n",
    "\n",
    "loss=tf.reduce_mean(tf.squared_difference(output, y))\n",
    "regularizer=tf.reduce_sum([tf.nn.l2_loss(W1), tf.nn.l2_loss(W2), tf.nn.l2_loss(W2g), tf.nn.l2_loss(W2z), tf.nn.l2_loss(Wconv), tf.nn.l2_loss(thetaconv)])\n",
    "total_loss=tf.reduce_sum(loss+L2_regularization*regularizer)\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate,name=\"Adam_op\").minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tr_iter =  335\n",
      "-----------------------------------------------\n",
      "Training epoch :  0\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 12.846389\n",
      "iter  50:\t Loss = 7.513391\n",
      "iter 100:\t Loss = 6.808902\n",
      "iter 150:\t Loss = 7.009159\n",
      "iter 200:\t Loss = 5.192062\n",
      "iter 250:\t Loss = 6.698910\n",
      "iter 300:\t Loss = 5.574524\n",
      "-----------------------------------------------\n",
      "Training epoch :  1\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 6.211347\n",
      "iter  50:\t Loss = 4.942992\n",
      "iter 100:\t Loss = 5.015193\n",
      "iter 150:\t Loss = 5.237680\n",
      "iter 200:\t Loss = 3.924478\n",
      "iter 250:\t Loss = 4.421286\n",
      "iter 300:\t Loss = 3.768161\n",
      "-----------------------------------------------\n",
      "Training epoch :  2\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 3.464777\n",
      "iter  50:\t Loss = 2.736320\n",
      "iter 100:\t Loss = 2.042642\n",
      "iter 150:\t Loss = 2.066844\n",
      "iter 200:\t Loss = 1.548259\n",
      "iter 250:\t Loss = 1.266353\n",
      "iter 300:\t Loss = 1.307016\n",
      "-----------------------------------------------\n",
      "Training epoch :  3\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.925398\n",
      "iter  50:\t Loss = 1.160279\n",
      "iter 100:\t Loss = 0.714516\n",
      "iter 150:\t Loss = 1.005587\n",
      "iter 200:\t Loss = 0.993405\n",
      "iter 250:\t Loss = 0.562035\n",
      "iter 300:\t Loss = 0.812925\n",
      "-----------------------------------------------\n",
      "Training epoch :  4\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.624096\n",
      "iter  50:\t Loss = 0.828118\n",
      "iter 100:\t Loss = 0.493098\n",
      "iter 150:\t Loss = 0.737225\n",
      "iter 200:\t Loss = 0.801276\n",
      "iter 250:\t Loss = 0.390679\n",
      "iter 300:\t Loss = 0.630783\n",
      "-----------------------------------------------\n",
      "Training epoch :  5\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.536959\n",
      "iter  50:\t Loss = 0.673768\n",
      "iter 100:\t Loss = 0.406677\n",
      "iter 150:\t Loss = 0.602228\n",
      "iter 200:\t Loss = 0.666746\n",
      "iter 250:\t Loss = 0.318103\n",
      "iter 300:\t Loss = 0.508984\n",
      "-----------------------------------------------\n",
      "Training epoch :  6\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.468412\n",
      "iter  50:\t Loss = 0.570753\n",
      "iter 100:\t Loss = 0.347467\n",
      "iter 150:\t Loss = 0.514025\n",
      "iter 200:\t Loss = 0.568887\n",
      "iter 250:\t Loss = 0.275091\n",
      "iter 300:\t Loss = 0.423714\n",
      "-----------------------------------------------\n",
      "Training epoch :  7\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.410919\n",
      "iter  50:\t Loss = 0.497859\n",
      "iter 100:\t Loss = 0.299784\n",
      "iter 150:\t Loss = 0.447336\n",
      "iter 200:\t Loss = 0.495926\n",
      "iter 250:\t Loss = 0.245146\n",
      "iter 300:\t Loss = 0.361120\n",
      "-----------------------------------------------\n",
      "Training epoch :  8\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.362890\n",
      "iter  50:\t Loss = 0.441734\n",
      "iter 100:\t Loss = 0.259901\n",
      "iter 150:\t Loss = 0.391064\n",
      "iter 200:\t Loss = 0.437989\n",
      "iter 250:\t Loss = 0.221066\n",
      "iter 300:\t Loss = 0.313545\n",
      "-----------------------------------------------\n",
      "Training epoch :  9\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.323236\n",
      "iter  50:\t Loss = 0.393632\n",
      "iter 100:\t Loss = 0.227582\n",
      "iter 150:\t Loss = 0.342491\n",
      "iter 200:\t Loss = 0.388597\n",
      "iter 250:\t Loss = 0.200374\n",
      "iter 300:\t Loss = 0.277271\n",
      "-----------------------------------------------\n",
      "Training epoch :  10\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.289365\n",
      "iter  50:\t Loss = 0.348709\n",
      "iter 100:\t Loss = 0.200585\n",
      "iter 150:\t Loss = 0.298996\n",
      "iter 200:\t Loss = 0.342991\n",
      "iter 250:\t Loss = 0.182070\n",
      "iter 300:\t Loss = 0.246500\n",
      "-----------------------------------------------\n",
      "Training epoch :  11\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.259312\n",
      "iter  50:\t Loss = 0.306237\n",
      "iter 100:\t Loss = 0.176537\n",
      "iter 150:\t Loss = 0.258335\n",
      "iter 200:\t Loss = 0.300043\n",
      "iter 250:\t Loss = 0.165173\n",
      "iter 300:\t Loss = 0.218736\n",
      "-----------------------------------------------\n",
      "Training epoch :  12\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.233135\n",
      "iter  50:\t Loss = 0.269062\n",
      "iter 100:\t Loss = 0.156432\n",
      "iter 150:\t Loss = 0.222531\n",
      "iter 200:\t Loss = 0.262916\n",
      "iter 250:\t Loss = 0.151266\n",
      "iter 300:\t Loss = 0.194549\n",
      "-----------------------------------------------\n",
      "Training epoch :  13\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.210836\n",
      "iter  50:\t Loss = 0.238890\n",
      "iter 100:\t Loss = 0.141322\n",
      "iter 150:\t Loss = 0.194016\n",
      "iter 200:\t Loss = 0.233683\n",
      "iter 250:\t Loss = 0.140661\n",
      "iter 300:\t Loss = 0.174820\n",
      "-----------------------------------------------\n",
      "Training epoch :  14\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.192709\n",
      "iter  50:\t Loss = 0.215094\n",
      "iter 100:\t Loss = 0.129700\n",
      "iter 150:\t Loss = 0.172571\n",
      "iter 200:\t Loss = 0.211239\n",
      "iter 250:\t Loss = 0.132191\n",
      "iter 300:\t Loss = 0.159155\n",
      "-----------------------------------------------\n",
      "Training epoch :  15\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.177742\n",
      "iter  50:\t Loss = 0.196173\n",
      "iter 100:\t Loss = 0.120356\n",
      "iter 150:\t Loss = 0.157039\n",
      "iter 200:\t Loss = 0.193510\n",
      "iter 250:\t Loss = 0.124836\n",
      "iter 300:\t Loss = 0.146598\n",
      "-----------------------------------------------\n",
      "Training epoch :  16\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.164631\n",
      "iter  50:\t Loss = 0.180432\n",
      "iter 100:\t Loss = 0.112318\n",
      "iter 150:\t Loss = 0.145644\n",
      "iter 200:\t Loss = 0.179045\n",
      "iter 250:\t Loss = 0.118241\n",
      "iter 300:\t Loss = 0.136214\n",
      "-----------------------------------------------\n",
      "Training epoch :  17\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.152619\n",
      "iter  50:\t Loss = 0.166906\n",
      "iter 100:\t Loss = 0.105058\n",
      "iter 150:\t Loss = 0.136820\n",
      "iter 200:\t Loss = 0.167124\n",
      "iter 250:\t Loss = 0.112337\n",
      "iter 300:\t Loss = 0.127373\n",
      "-----------------------------------------------\n",
      "Training epoch :  18\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.141538\n",
      "iter  50:\t Loss = 0.155071\n",
      "iter 100:\t Loss = 0.098313\n",
      "iter 150:\t Loss = 0.129693\n",
      "iter 200:\t Loss = 0.157264\n",
      "iter 250:\t Loss = 0.106859\n",
      "iter 300:\t Loss = 0.119825\n",
      "-----------------------------------------------\n",
      "Training epoch :  19\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.131743\n",
      "iter  50:\t Loss = 0.144595\n",
      "iter 100:\t Loss = 0.091919\n",
      "iter 150:\t Loss = 0.123694\n",
      "iter 200:\t Loss = 0.149096\n",
      "iter 250:\t Loss = 0.101255\n",
      "iter 300:\t Loss = 0.113333\n",
      "-----------------------------------------------\n",
      "Training epoch :  20\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.123207\n",
      "iter  50:\t Loss = 0.135776\n",
      "iter 100:\t Loss = 0.085955\n",
      "iter 150:\t Loss = 0.118207\n",
      "iter 200:\t Loss = 0.142090\n",
      "iter 250:\t Loss = 0.095983\n",
      "iter 300:\t Loss = 0.107558\n",
      "-----------------------------------------------\n",
      "Training epoch :  21\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.115581\n",
      "iter  50:\t Loss = 0.128730\n",
      "iter 100:\t Loss = 0.080619\n",
      "iter 150:\t Loss = 0.113619\n",
      "iter 200:\t Loss = 0.135954\n",
      "iter 250:\t Loss = 0.091660\n",
      "iter 300:\t Loss = 0.102527\n",
      "-----------------------------------------------\n",
      "Training epoch :  22\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.109233\n",
      "iter  50:\t Loss = 0.123073\n",
      "iter 100:\t Loss = 0.076095\n",
      "iter 150:\t Loss = 0.109880\n",
      "iter 200:\t Loss = 0.130724\n",
      "iter 250:\t Loss = 0.088199\n",
      "iter 300:\t Loss = 0.098251\n",
      "-----------------------------------------------\n",
      "Training epoch :  23\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.104156\n",
      "iter  50:\t Loss = 0.118467\n",
      "iter 100:\t Loss = 0.072422\n",
      "iter 150:\t Loss = 0.106633\n",
      "iter 200:\t Loss = 0.126355\n",
      "iter 250:\t Loss = 0.085406\n",
      "iter 300:\t Loss = 0.094624\n",
      "-----------------------------------------------\n",
      "Training epoch :  24\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.100125\n",
      "iter  50:\t Loss = 0.114641\n",
      "iter 100:\t Loss = 0.069474\n",
      "iter 150:\t Loss = 0.103678\n",
      "iter 200:\t Loss = 0.122722\n",
      "iter 250:\t Loss = 0.083110\n",
      "iter 300:\t Loss = 0.091515\n",
      "-----------------------------------------------\n",
      "Training epoch :  25\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.096917\n",
      "iter  50:\t Loss = 0.111391\n",
      "iter 100:\t Loss = 0.067068\n",
      "iter 150:\t Loss = 0.100970\n",
      "iter 200:\t Loss = 0.119667\n",
      "iter 250:\t Loss = 0.081183\n",
      "iter 300:\t Loss = 0.088817\n",
      "-----------------------------------------------\n",
      "Training epoch :  26\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.094354\n",
      "iter  50:\t Loss = 0.108560\n",
      "iter 100:\t Loss = 0.065053\n",
      "iter 150:\t Loss = 0.098513\n",
      "iter 200:\t Loss = 0.117052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 250:\t Loss = 0.079528\n",
      "iter 300:\t Loss = 0.086455\n",
      "-----------------------------------------------\n",
      "Training epoch :  27\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.092298\n",
      "iter  50:\t Loss = 0.106034\n",
      "iter 100:\t Loss = 0.063330\n",
      "iter 150:\t Loss = 0.096296\n",
      "iter 200:\t Loss = 0.114768\n",
      "iter 250:\t Loss = 0.078078\n",
      "iter 300:\t Loss = 0.084372\n",
      "-----------------------------------------------\n",
      "Training epoch :  28\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.090645\n",
      "iter  50:\t Loss = 0.103739\n",
      "iter 100:\t Loss = 0.061840\n",
      "iter 150:\t Loss = 0.094294\n",
      "iter 200:\t Loss = 0.112735\n",
      "iter 250:\t Loss = 0.076785\n",
      "iter 300:\t Loss = 0.082523\n",
      "-----------------------------------------------\n",
      "Training epoch :  29\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.089310\n",
      "iter  50:\t Loss = 0.101629\n",
      "iter 100:\t Loss = 0.060551\n",
      "iter 150:\t Loss = 0.092473\n",
      "iter 200:\t Loss = 0.110890\n",
      "iter 250:\t Loss = 0.075613\n",
      "iter 300:\t Loss = 0.080871\n",
      "-----------------------------------------------\n",
      "Training epoch :  30\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.088229\n",
      "iter  50:\t Loss = 0.099682\n",
      "iter 100:\t Loss = 0.059439\n",
      "iter 150:\t Loss = 0.090803\n",
      "iter 200:\t Loss = 0.109184\n",
      "iter 250:\t Loss = 0.074537\n",
      "iter 300:\t Loss = 0.079386\n",
      "-----------------------------------------------\n",
      "Training epoch :  31\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.087346\n",
      "iter  50:\t Loss = 0.097894\n",
      "iter 100:\t Loss = 0.058482\n",
      "iter 150:\t Loss = 0.089261\n",
      "iter 200:\t Loss = 0.107583\n",
      "iter 250:\t Loss = 0.073542\n",
      "iter 300:\t Loss = 0.078045\n",
      "-----------------------------------------------\n",
      "Training epoch :  32\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.086612\n",
      "iter  50:\t Loss = 0.096267\n",
      "iter 100:\t Loss = 0.057654\n",
      "iter 150:\t Loss = 0.087833\n",
      "iter 200:\t Loss = 0.106067\n",
      "iter 250:\t Loss = 0.072621\n",
      "iter 300:\t Loss = 0.076833\n",
      "-----------------------------------------------\n",
      "Training epoch :  33\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.085986\n",
      "iter  50:\t Loss = 0.094805\n",
      "iter 100:\t Loss = 0.056929\n",
      "iter 150:\t Loss = 0.086506\n",
      "iter 200:\t Loss = 0.104630\n",
      "iter 250:\t Loss = 0.071770\n",
      "iter 300:\t Loss = 0.075739\n",
      "-----------------------------------------------\n",
      "Training epoch :  34\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.085437\n",
      "iter  50:\t Loss = 0.093504\n",
      "iter 100:\t Loss = 0.056280\n",
      "iter 150:\t Loss = 0.085271\n",
      "iter 200:\t Loss = 0.103274\n",
      "iter 250:\t Loss = 0.070991\n",
      "iter 300:\t Loss = 0.074754\n",
      "-----------------------------------------------\n",
      "Training epoch :  35\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.084946\n",
      "iter  50:\t Loss = 0.092358\n",
      "iter 100:\t Loss = 0.055690\n",
      "iter 150:\t Loss = 0.084119\n",
      "iter 200:\t Loss = 0.102005\n",
      "iter 250:\t Loss = 0.070285\n",
      "iter 300:\t Loss = 0.073873\n",
      "-----------------------------------------------\n",
      "Training epoch :  36\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.084501\n",
      "iter  50:\t Loss = 0.091356\n",
      "iter 100:\t Loss = 0.055149\n",
      "iter 150:\t Loss = 0.083044\n",
      "iter 200:\t Loss = 0.100825\n",
      "iter 250:\t Loss = 0.069652\n",
      "iter 300:\t Loss = 0.073089\n",
      "-----------------------------------------------\n",
      "Training epoch :  37\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.084096\n",
      "iter  50:\t Loss = 0.090492\n",
      "iter 100:\t Loss = 0.054648\n",
      "iter 150:\t Loss = 0.082041\n",
      "iter 200:\t Loss = 0.099733\n",
      "iter 250:\t Loss = 0.069088\n",
      "iter 300:\t Loss = 0.072392\n",
      "-----------------------------------------------\n",
      "Training epoch :  38\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.083730\n",
      "iter  50:\t Loss = 0.089752\n",
      "iter 100:\t Loss = 0.054186\n",
      "iter 150:\t Loss = 0.081106\n",
      "iter 200:\t Loss = 0.098728\n",
      "iter 250:\t Loss = 0.068589\n",
      "iter 300:\t Loss = 0.071771\n",
      "-----------------------------------------------\n",
      "Training epoch :  39\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.083398\n",
      "iter  50:\t Loss = 0.089122\n",
      "iter 100:\t Loss = 0.053759\n",
      "iter 150:\t Loss = 0.080236\n",
      "iter 200:\t Loss = 0.097804\n",
      "iter 250:\t Loss = 0.068147\n",
      "iter 300:\t Loss = 0.071216\n",
      "-----------------------------------------------\n",
      "Training epoch :  40\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.083099\n",
      "iter  50:\t Loss = 0.088585\n",
      "iter 100:\t Loss = 0.053363\n",
      "iter 150:\t Loss = 0.079427\n",
      "iter 200:\t Loss = 0.096953\n",
      "iter 250:\t Loss = 0.067756\n",
      "iter 300:\t Loss = 0.070717\n",
      "-----------------------------------------------\n",
      "Training epoch :  41\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.082830\n",
      "iter  50:\t Loss = 0.088125\n",
      "iter 100:\t Loss = 0.052996\n",
      "iter 150:\t Loss = 0.078674\n",
      "iter 200:\t Loss = 0.096170\n",
      "iter 250:\t Loss = 0.067407\n",
      "iter 300:\t Loss = 0.070265\n",
      "-----------------------------------------------\n",
      "Training epoch :  42\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.082588\n",
      "iter  50:\t Loss = 0.087726\n",
      "iter 100:\t Loss = 0.052653\n",
      "iter 150:\t Loss = 0.077973\n",
      "iter 200:\t Loss = 0.095445\n",
      "iter 250:\t Loss = 0.067095\n",
      "iter 300:\t Loss = 0.069851\n",
      "-----------------------------------------------\n",
      "Training epoch :  43\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.082369\n",
      "iter  50:\t Loss = 0.087379\n",
      "iter 100:\t Loss = 0.052333\n",
      "iter 150:\t Loss = 0.077318\n",
      "iter 200:\t Loss = 0.094770\n",
      "iter 250:\t Loss = 0.066810\n",
      "iter 300:\t Loss = 0.069468\n",
      "-----------------------------------------------\n",
      "Training epoch :  44\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.082173\n",
      "iter  50:\t Loss = 0.087074\n",
      "iter 100:\t Loss = 0.052033\n",
      "iter 150:\t Loss = 0.076704\n",
      "iter 200:\t Loss = 0.094139\n",
      "iter 250:\t Loss = 0.066547\n",
      "iter 300:\t Loss = 0.069108\n",
      "-----------------------------------------------\n",
      "Training epoch :  45\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081995\n",
      "iter  50:\t Loss = 0.086804\n",
      "iter 100:\t Loss = 0.051750\n",
      "iter 150:\t Loss = 0.076125\n",
      "iter 200:\t Loss = 0.093544\n",
      "iter 250:\t Loss = 0.066299\n",
      "iter 300:\t Loss = 0.068765\n",
      "-----------------------------------------------\n",
      "Training epoch :  46\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081835\n",
      "iter  50:\t Loss = 0.086562\n",
      "iter 100:\t Loss = 0.051483\n",
      "iter 150:\t Loss = 0.075574\n",
      "iter 200:\t Loss = 0.092978\n",
      "iter 250:\t Loss = 0.066060\n",
      "iter 300:\t Loss = 0.068430\n",
      "-----------------------------------------------\n",
      "Training epoch :  47\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081689\n",
      "iter  50:\t Loss = 0.086341\n",
      "iter 100:\t Loss = 0.051232\n",
      "iter 150:\t Loss = 0.075047\n",
      "iter 200:\t Loss = 0.092438\n",
      "iter 250:\t Loss = 0.065827\n",
      "iter 300:\t Loss = 0.068100\n",
      "-----------------------------------------------\n",
      "Training epoch :  48\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081556\n",
      "iter  50:\t Loss = 0.086132\n",
      "iter 100:\t Loss = 0.050995\n",
      "iter 150:\t Loss = 0.074541\n",
      "iter 200:\t Loss = 0.091921\n",
      "iter 250:\t Loss = 0.065597\n",
      "iter 300:\t Loss = 0.067770\n",
      "-----------------------------------------------\n",
      "Training epoch :  49\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081436\n",
      "iter  50:\t Loss = 0.085931\n",
      "iter 100:\t Loss = 0.050770\n",
      "iter 150:\t Loss = 0.074055\n",
      "iter 200:\t Loss = 0.091427\n",
      "iter 250:\t Loss = 0.065371\n",
      "iter 300:\t Loss = 0.067436\n",
      "-----------------------------------------------\n",
      "Training epoch :  50\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081326\n",
      "iter  50:\t Loss = 0.085731\n",
      "iter 100:\t Loss = 0.050555\n",
      "iter 150:\t Loss = 0.073588\n",
      "iter 200:\t Loss = 0.090956\n",
      "iter 250:\t Loss = 0.065149\n",
      "iter 300:\t Loss = 0.067098\n",
      "-----------------------------------------------\n",
      "Training epoch :  51\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081229\n",
      "iter  50:\t Loss = 0.085533\n",
      "iter 100:\t Loss = 0.050350\n",
      "iter 150:\t Loss = 0.073141\n",
      "iter 200:\t Loss = 0.090511\n",
      "iter 250:\t Loss = 0.064935\n",
      "iter 300:\t Loss = 0.066755\n",
      "-----------------------------------------------\n",
      "Training epoch :  52\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081143\n",
      "iter  50:\t Loss = 0.085338\n",
      "iter 100:\t Loss = 0.050151\n",
      "iter 150:\t Loss = 0.072711\n",
      "iter 200:\t Loss = 0.090090\n",
      "iter 250:\t Loss = 0.064730\n",
      "iter 300:\t Loss = 0.066405\n",
      "-----------------------------------------------\n",
      "Training epoch :  53\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081071\n",
      "iter  50:\t Loss = 0.085152\n",
      "iter 100:\t Loss = 0.049958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 150:\t Loss = 0.072296\n",
      "iter 200:\t Loss = 0.089696\n",
      "iter 250:\t Loss = 0.064536\n",
      "iter 300:\t Loss = 0.066046\n",
      "-----------------------------------------------\n",
      "Training epoch :  54\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081013\n",
      "iter  50:\t Loss = 0.084979\n",
      "iter 100:\t Loss = 0.049769\n",
      "iter 150:\t Loss = 0.071889\n",
      "iter 200:\t Loss = 0.089328\n",
      "iter 250:\t Loss = 0.064357\n",
      "iter 300:\t Loss = 0.065671\n",
      "-----------------------------------------------\n",
      "Training epoch :  55\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080970\n",
      "iter  50:\t Loss = 0.084825\n",
      "iter 100:\t Loss = 0.049581\n",
      "iter 150:\t Loss = 0.071479\n",
      "iter 200:\t Loss = 0.088985\n",
      "iter 250:\t Loss = 0.064189\n",
      "iter 300:\t Loss = 0.065269\n",
      "-----------------------------------------------\n",
      "Training epoch :  56\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080943\n",
      "iter  50:\t Loss = 0.084691\n",
      "iter 100:\t Loss = 0.049386\n",
      "iter 150:\t Loss = 0.071056\n",
      "iter 200:\t Loss = 0.088663\n",
      "iter 250:\t Loss = 0.064022\n",
      "iter 300:\t Loss = 0.064827\n",
      "-----------------------------------------------\n",
      "Training epoch :  57\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080926\n",
      "iter  50:\t Loss = 0.084566\n",
      "iter 100:\t Loss = 0.049172\n",
      "iter 150:\t Loss = 0.070618\n",
      "iter 200:\t Loss = 0.088355\n",
      "iter 250:\t Loss = 0.063836\n",
      "iter 300:\t Loss = 0.064355\n",
      "-----------------------------------------------\n",
      "Training epoch :  58\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080917\n",
      "iter  50:\t Loss = 0.084439\n",
      "iter 100:\t Loss = 0.048935\n",
      "iter 150:\t Loss = 0.070191\n",
      "iter 200:\t Loss = 0.088056\n",
      "iter 250:\t Loss = 0.063617\n",
      "iter 300:\t Loss = 0.063889\n",
      "-----------------------------------------------\n",
      "Training epoch :  59\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080916\n",
      "iter  50:\t Loss = 0.084311\n",
      "iter 100:\t Loss = 0.048689\n",
      "iter 150:\t Loss = 0.069793\n",
      "iter 200:\t Loss = 0.087762\n",
      "iter 250:\t Loss = 0.063371\n",
      "iter 300:\t Loss = 0.063461\n",
      "-----------------------------------------------\n",
      "Training epoch :  60\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080925\n",
      "iter  50:\t Loss = 0.084192\n",
      "iter 100:\t Loss = 0.048444\n",
      "iter 150:\t Loss = 0.069421\n",
      "iter 200:\t Loss = 0.087471\n",
      "iter 250:\t Loss = 0.063112\n",
      "iter 300:\t Loss = 0.063075\n",
      "-----------------------------------------------\n",
      "Training epoch :  61\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080940\n",
      "iter  50:\t Loss = 0.084082\n",
      "iter 100:\t Loss = 0.048206\n",
      "iter 150:\t Loss = 0.069070\n",
      "iter 200:\t Loss = 0.087176\n",
      "iter 250:\t Loss = 0.062856\n",
      "iter 300:\t Loss = 0.062724\n",
      "-----------------------------------------------\n",
      "Training epoch :  62\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080958\n",
      "iter  50:\t Loss = 0.083977\n",
      "iter 100:\t Loss = 0.047972\n",
      "iter 150:\t Loss = 0.068736\n",
      "iter 200:\t Loss = 0.086875\n",
      "iter 250:\t Loss = 0.062612\n",
      "iter 300:\t Loss = 0.062400\n",
      "-----------------------------------------------\n",
      "Training epoch :  63\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080977\n",
      "iter  50:\t Loss = 0.083876\n",
      "iter 100:\t Loss = 0.047740\n",
      "iter 150:\t Loss = 0.068418\n",
      "iter 200:\t Loss = 0.086568\n",
      "iter 250:\t Loss = 0.062386\n",
      "iter 300:\t Loss = 0.062100\n",
      "-----------------------------------------------\n",
      "Training epoch :  64\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080998\n",
      "iter  50:\t Loss = 0.083777\n",
      "iter 100:\t Loss = 0.047508\n",
      "iter 150:\t Loss = 0.068115\n",
      "iter 200:\t Loss = 0.086253\n",
      "iter 250:\t Loss = 0.062179\n",
      "iter 300:\t Loss = 0.061821\n",
      "-----------------------------------------------\n",
      "Training epoch :  65\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081021\n",
      "iter  50:\t Loss = 0.083679\n",
      "iter 100:\t Loss = 0.047276\n",
      "iter 150:\t Loss = 0.067825\n",
      "iter 200:\t Loss = 0.085933\n",
      "iter 250:\t Loss = 0.061992\n",
      "iter 300:\t Loss = 0.061560\n",
      "-----------------------------------------------\n",
      "Training epoch :  66\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081045\n",
      "iter  50:\t Loss = 0.083583\n",
      "iter 100:\t Loss = 0.047043\n",
      "iter 150:\t Loss = 0.067547\n",
      "iter 200:\t Loss = 0.085607\n",
      "iter 250:\t Loss = 0.061824\n",
      "iter 300:\t Loss = 0.061319\n",
      "-----------------------------------------------\n",
      "Training epoch :  67\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081071\n",
      "iter  50:\t Loss = 0.083488\n",
      "iter 100:\t Loss = 0.046809\n",
      "iter 150:\t Loss = 0.067280\n",
      "iter 200:\t Loss = 0.085277\n",
      "iter 250:\t Loss = 0.061672\n",
      "iter 300:\t Loss = 0.061094\n",
      "-----------------------------------------------\n",
      "Training epoch :  68\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081096\n",
      "iter  50:\t Loss = 0.083395\n",
      "iter 100:\t Loss = 0.046576\n",
      "iter 150:\t Loss = 0.067025\n",
      "iter 200:\t Loss = 0.084944\n",
      "iter 250:\t Loss = 0.061536\n",
      "iter 300:\t Loss = 0.060886\n",
      "-----------------------------------------------\n",
      "Training epoch :  69\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081121\n",
      "iter  50:\t Loss = 0.083303\n",
      "iter 100:\t Loss = 0.046345\n",
      "iter 150:\t Loss = 0.066780\n",
      "iter 200:\t Loss = 0.084608\n",
      "iter 250:\t Loss = 0.061414\n",
      "iter 300:\t Loss = 0.060692\n",
      "-----------------------------------------------\n",
      "Training epoch :  70\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081144\n",
      "iter  50:\t Loss = 0.083213\n",
      "iter 100:\t Loss = 0.046116\n",
      "iter 150:\t Loss = 0.066546\n",
      "iter 200:\t Loss = 0.084271\n",
      "iter 250:\t Loss = 0.061303\n",
      "iter 300:\t Loss = 0.060513\n",
      "-----------------------------------------------\n",
      "Training epoch :  71\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081165\n",
      "iter  50:\t Loss = 0.083124\n",
      "iter 100:\t Loss = 0.045891\n",
      "iter 150:\t Loss = 0.066323\n",
      "iter 200:\t Loss = 0.083934\n",
      "iter 250:\t Loss = 0.061201\n",
      "iter 300:\t Loss = 0.060346\n",
      "-----------------------------------------------\n",
      "Training epoch :  72\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081182\n",
      "iter  50:\t Loss = 0.083035\n",
      "iter 100:\t Loss = 0.045670\n",
      "iter 150:\t Loss = 0.066111\n",
      "iter 200:\t Loss = 0.083598\n",
      "iter 250:\t Loss = 0.061108\n",
      "iter 300:\t Loss = 0.060190\n",
      "-----------------------------------------------\n",
      "Training epoch :  73\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081195\n",
      "iter  50:\t Loss = 0.082948\n",
      "iter 100:\t Loss = 0.045453\n",
      "iter 150:\t Loss = 0.065910\n",
      "iter 200:\t Loss = 0.083264\n",
      "iter 250:\t Loss = 0.061022\n",
      "iter 300:\t Loss = 0.060043\n",
      "-----------------------------------------------\n",
      "Training epoch :  74\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081204\n",
      "iter  50:\t Loss = 0.082861\n",
      "iter 100:\t Loss = 0.045242\n",
      "iter 150:\t Loss = 0.065719\n",
      "iter 200:\t Loss = 0.082933\n",
      "iter 250:\t Loss = 0.060941\n",
      "iter 300:\t Loss = 0.059904\n",
      "-----------------------------------------------\n",
      "Training epoch :  75\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081209\n",
      "iter  50:\t Loss = 0.082775\n",
      "iter 100:\t Loss = 0.045037\n",
      "iter 150:\t Loss = 0.065537\n",
      "iter 200:\t Loss = 0.082606\n",
      "iter 250:\t Loss = 0.060865\n",
      "iter 300:\t Loss = 0.059772\n",
      "-----------------------------------------------\n",
      "Training epoch :  76\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081210\n",
      "iter  50:\t Loss = 0.082691\n",
      "iter 100:\t Loss = 0.044837\n",
      "iter 150:\t Loss = 0.065365\n",
      "iter 200:\t Loss = 0.082285\n",
      "iter 250:\t Loss = 0.060793\n",
      "iter 300:\t Loss = 0.059645\n",
      "-----------------------------------------------\n",
      "Training epoch :  77\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081207\n",
      "iter  50:\t Loss = 0.082607\n",
      "iter 100:\t Loss = 0.044643\n",
      "iter 150:\t Loss = 0.065201\n",
      "iter 200:\t Loss = 0.081970\n",
      "iter 250:\t Loss = 0.060724\n",
      "iter 300:\t Loss = 0.059522\n",
      "-----------------------------------------------\n",
      "Training epoch :  78\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081201\n",
      "iter  50:\t Loss = 0.082524\n",
      "iter 100:\t Loss = 0.044454\n",
      "iter 150:\t Loss = 0.065045\n",
      "iter 200:\t Loss = 0.081661\n",
      "iter 250:\t Loss = 0.060657\n",
      "iter 300:\t Loss = 0.059402\n",
      "-----------------------------------------------\n",
      "Training epoch :  79\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081191\n",
      "iter  50:\t Loss = 0.082442\n",
      "iter 100:\t Loss = 0.044272\n",
      "iter 150:\t Loss = 0.064896\n",
      "iter 200:\t Loss = 0.081360\n",
      "iter 250:\t Loss = 0.060593\n",
      "iter 300:\t Loss = 0.059285\n",
      "-----------------------------------------------\n",
      "Training epoch :  80\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.082361\n",
      "iter 100:\t Loss = 0.044095\n",
      "iter 150:\t Loss = 0.064754\n",
      "iter 200:\t Loss = 0.081066\n",
      "iter 250:\t Loss = 0.060530\n",
      "iter 300:\t Loss = 0.059169\n",
      "-----------------------------------------------\n",
      "Training epoch :  81\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081164\n",
      "iter  50:\t Loss = 0.082281\n",
      "iter 100:\t Loss = 0.043924\n",
      "iter 150:\t Loss = 0.064618\n",
      "iter 200:\t Loss = 0.080781\n",
      "iter 250:\t Loss = 0.060470\n",
      "iter 300:\t Loss = 0.059053\n",
      "-----------------------------------------------\n",
      "Training epoch :  82\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081147\n",
      "iter  50:\t Loss = 0.082202\n",
      "iter 100:\t Loss = 0.043759\n",
      "iter 150:\t Loss = 0.064486\n",
      "iter 200:\t Loss = 0.080504\n",
      "iter 250:\t Loss = 0.060412\n",
      "iter 300:\t Loss = 0.058938\n",
      "-----------------------------------------------\n",
      "Training epoch :  83\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081129\n",
      "iter  50:\t Loss = 0.082124\n",
      "iter 100:\t Loss = 0.043599\n",
      "iter 150:\t Loss = 0.064359\n",
      "iter 200:\t Loss = 0.080234\n",
      "iter 250:\t Loss = 0.060356\n",
      "iter 300:\t Loss = 0.058823\n",
      "-----------------------------------------------\n",
      "Training epoch :  84\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081110\n",
      "iter  50:\t Loss = 0.082045\n",
      "iter 100:\t Loss = 0.043445\n",
      "iter 150:\t Loss = 0.064235\n",
      "iter 200:\t Loss = 0.079971\n",
      "iter 250:\t Loss = 0.060302\n",
      "iter 300:\t Loss = 0.058707\n",
      "-----------------------------------------------\n",
      "Training epoch :  85\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081090\n",
      "iter  50:\t Loss = 0.081968\n",
      "iter 100:\t Loss = 0.043296\n",
      "iter 150:\t Loss = 0.064114\n",
      "iter 200:\t Loss = 0.079716\n",
      "iter 250:\t Loss = 0.060250\n",
      "iter 300:\t Loss = 0.058591\n",
      "-----------------------------------------------\n",
      "Training epoch :  86\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081070\n",
      "iter  50:\t Loss = 0.081890\n",
      "iter 100:\t Loss = 0.043152\n",
      "iter 150:\t Loss = 0.063996\n",
      "iter 200:\t Loss = 0.079467\n",
      "iter 250:\t Loss = 0.060201\n",
      "iter 300:\t Loss = 0.058474\n",
      "-----------------------------------------------\n",
      "Training epoch :  87\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081049\n",
      "iter  50:\t Loss = 0.081812\n",
      "iter 100:\t Loss = 0.043014\n",
      "iter 150:\t Loss = 0.063880\n",
      "iter 200:\t Loss = 0.079225\n",
      "iter 250:\t Loss = 0.060154\n",
      "iter 300:\t Loss = 0.058355\n",
      "-----------------------------------------------\n",
      "Training epoch :  88\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081028\n",
      "iter  50:\t Loss = 0.081732\n",
      "iter 100:\t Loss = 0.042880\n",
      "iter 150:\t Loss = 0.063765\n",
      "iter 200:\t Loss = 0.078988\n",
      "iter 250:\t Loss = 0.060110\n",
      "iter 300:\t Loss = 0.058236\n",
      "-----------------------------------------------\n",
      "Training epoch :  89\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.081007\n",
      "iter  50:\t Loss = 0.081652\n",
      "iter 100:\t Loss = 0.042751\n",
      "iter 150:\t Loss = 0.063650\n",
      "iter 200:\t Loss = 0.078757\n",
      "iter 250:\t Loss = 0.060069\n",
      "iter 300:\t Loss = 0.058114\n",
      "-----------------------------------------------\n",
      "Training epoch :  90\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080985\n",
      "iter  50:\t Loss = 0.081570\n",
      "iter 100:\t Loss = 0.042626\n",
      "iter 150:\t Loss = 0.063537\n",
      "iter 200:\t Loss = 0.078530\n",
      "iter 250:\t Loss = 0.060030\n",
      "iter 300:\t Loss = 0.057991\n",
      "-----------------------------------------------\n",
      "Training epoch :  91\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080961\n",
      "iter  50:\t Loss = 0.081485\n",
      "iter 100:\t Loss = 0.042505\n",
      "iter 150:\t Loss = 0.063424\n",
      "iter 200:\t Loss = 0.078308\n",
      "iter 250:\t Loss = 0.059993\n",
      "iter 300:\t Loss = 0.057866\n",
      "-----------------------------------------------\n",
      "Training epoch :  92\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080936\n",
      "iter  50:\t Loss = 0.081399\n",
      "iter 100:\t Loss = 0.042387\n",
      "iter 150:\t Loss = 0.063310\n",
      "iter 200:\t Loss = 0.078090\n",
      "iter 250:\t Loss = 0.059958\n",
      "iter 300:\t Loss = 0.057738\n",
      "-----------------------------------------------\n",
      "Training epoch :  93\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080909\n",
      "iter  50:\t Loss = 0.081309\n",
      "iter 100:\t Loss = 0.042272\n",
      "iter 150:\t Loss = 0.063197\n",
      "iter 200:\t Loss = 0.077876\n",
      "iter 250:\t Loss = 0.059924\n",
      "iter 300:\t Loss = 0.057606\n",
      "-----------------------------------------------\n",
      "Training epoch :  94\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080880\n",
      "iter  50:\t Loss = 0.081217\n",
      "iter 100:\t Loss = 0.042159\n",
      "iter 150:\t Loss = 0.063082\n",
      "iter 200:\t Loss = 0.077664\n",
      "iter 250:\t Loss = 0.059891\n",
      "iter 300:\t Loss = 0.057471\n",
      "-----------------------------------------------\n",
      "Training epoch :  95\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080846\n",
      "iter  50:\t Loss = 0.081122\n",
      "iter 100:\t Loss = 0.042048\n",
      "iter 150:\t Loss = 0.062967\n",
      "iter 200:\t Loss = 0.077456\n",
      "iter 250:\t Loss = 0.059857\n",
      "iter 300:\t Loss = 0.057331\n",
      "-----------------------------------------------\n",
      "Training epoch :  96\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080809\n",
      "iter  50:\t Loss = 0.081025\n",
      "iter 100:\t Loss = 0.041938\n",
      "iter 150:\t Loss = 0.062851\n",
      "iter 200:\t Loss = 0.077250\n",
      "iter 250:\t Loss = 0.059821\n",
      "iter 300:\t Loss = 0.057185\n",
      "-----------------------------------------------\n",
      "Training epoch :  97\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080766\n",
      "iter  50:\t Loss = 0.080927\n",
      "iter 100:\t Loss = 0.041830\n",
      "iter 150:\t Loss = 0.062734\n",
      "iter 200:\t Loss = 0.077045\n",
      "iter 250:\t Loss = 0.059782\n",
      "iter 300:\t Loss = 0.057031\n",
      "-----------------------------------------------\n",
      "Training epoch :  98\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080718\n",
      "iter  50:\t Loss = 0.080828\n",
      "iter 100:\t Loss = 0.041721\n",
      "iter 150:\t Loss = 0.062615\n",
      "iter 200:\t Loss = 0.076842\n",
      "iter 250:\t Loss = 0.059738\n",
      "iter 300:\t Loss = 0.056868\n",
      "-----------------------------------------------\n",
      "Training epoch :  99\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080663\n",
      "iter  50:\t Loss = 0.080732\n",
      "iter 100:\t Loss = 0.041612\n",
      "iter 150:\t Loss = 0.062494\n",
      "iter 200:\t Loss = 0.076639\n",
      "iter 250:\t Loss = 0.059688\n",
      "iter 300:\t Loss = 0.056693\n",
      "-----------------------------------------------\n",
      "Training epoch :  100\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080603\n",
      "iter  50:\t Loss = 0.080640\n",
      "iter 100:\t Loss = 0.041503\n",
      "iter 150:\t Loss = 0.062372\n",
      "iter 200:\t Loss = 0.076436\n",
      "iter 250:\t Loss = 0.059630\n",
      "iter 300:\t Loss = 0.056504\n",
      "-----------------------------------------------\n",
      "Training epoch :  101\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080538\n",
      "iter  50:\t Loss = 0.080554\n",
      "iter 100:\t Loss = 0.041394\n",
      "iter 150:\t Loss = 0.062248\n",
      "iter 200:\t Loss = 0.076232\n",
      "iter 250:\t Loss = 0.059564\n",
      "iter 300:\t Loss = 0.056299\n",
      "-----------------------------------------------\n",
      "Training epoch :  102\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080469\n",
      "iter  50:\t Loss = 0.080476\n",
      "iter 100:\t Loss = 0.041286\n",
      "iter 150:\t Loss = 0.062123\n",
      "iter 200:\t Loss = 0.076027\n",
      "iter 250:\t Loss = 0.059492\n",
      "iter 300:\t Loss = 0.056076\n",
      "-----------------------------------------------\n",
      "Training epoch :  103\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080397\n",
      "iter  50:\t Loss = 0.080406\n",
      "iter 100:\t Loss = 0.041183\n",
      "iter 150:\t Loss = 0.061998\n",
      "iter 200:\t Loss = 0.075821\n",
      "iter 250:\t Loss = 0.059417\n",
      "iter 300:\t Loss = 0.055836\n",
      "-----------------------------------------------\n",
      "Training epoch :  104\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080324\n",
      "iter  50:\t Loss = 0.080341\n",
      "iter 100:\t Loss = 0.041087\n",
      "iter 150:\t Loss = 0.061874\n",
      "iter 200:\t Loss = 0.075613\n",
      "iter 250:\t Loss = 0.059341\n",
      "iter 300:\t Loss = 0.055579\n",
      "-----------------------------------------------\n",
      "Training epoch :  105\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080249\n",
      "iter  50:\t Loss = 0.080278\n",
      "iter 100:\t Loss = 0.041004\n",
      "iter 150:\t Loss = 0.061752\n",
      "iter 200:\t Loss = 0.075400\n",
      "iter 250:\t Loss = 0.059269\n",
      "iter 300:\t Loss = 0.055309\n",
      "-----------------------------------------------\n",
      "Training epoch :  106\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080172\n",
      "iter  50:\t Loss = 0.080212\n",
      "iter 100:\t Loss = 0.040934\n",
      "iter 150:\t Loss = 0.061634\n",
      "iter 200:\t Loss = 0.075183\n",
      "iter 250:\t Loss = 0.059202\n",
      "iter 300:\t Loss = 0.055028\n",
      "-----------------------------------------------\n",
      "Training epoch :  107\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.080142\n",
      "iter 100:\t Loss = 0.040879\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.074961\n",
      "iter 250:\t Loss = 0.059140\n",
      "iter 300:\t Loss = 0.054739\n",
      "-----------------------------------------------\n",
      "Training epoch :  108\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.080007\n",
      "iter  50:\t Loss = 0.080066\n",
      "iter 100:\t Loss = 0.040838\n",
      "iter 150:\t Loss = 0.061419\n",
      "iter 200:\t Loss = 0.074733\n",
      "iter 250:\t Loss = 0.059083\n",
      "iter 300:\t Loss = 0.054443\n",
      "-----------------------------------------------\n",
      "Training epoch :  109\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079918\n",
      "iter  50:\t Loss = 0.079984\n",
      "iter 100:\t Loss = 0.040809\n",
      "iter 150:\t Loss = 0.061323\n",
      "iter 200:\t Loss = 0.074501\n",
      "iter 250:\t Loss = 0.059030\n",
      "iter 300:\t Loss = 0.054143\n",
      "-----------------------------------------------\n",
      "Training epoch :  110\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079826\n",
      "iter  50:\t Loss = 0.079896\n",
      "iter 100:\t Loss = 0.040790\n",
      "iter 150:\t Loss = 0.061238\n",
      "iter 200:\t Loss = 0.074266\n",
      "iter 250:\t Loss = 0.058978\n",
      "iter 300:\t Loss = 0.053839\n",
      "-----------------------------------------------\n",
      "Training epoch :  111\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079732\n",
      "iter  50:\t Loss = 0.079805\n",
      "iter 100:\t Loss = 0.040780\n",
      "iter 150:\t Loss = 0.061163\n",
      "iter 200:\t Loss = 0.074027\n",
      "iter 250:\t Loss = 0.058928\n",
      "iter 300:\t Loss = 0.053534\n",
      "-----------------------------------------------\n",
      "Training epoch :  112\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079635\n",
      "iter  50:\t Loss = 0.079711\n",
      "iter 100:\t Loss = 0.040779\n",
      "iter 150:\t Loss = 0.061099\n",
      "iter 200:\t Loss = 0.073787\n",
      "iter 250:\t Loss = 0.058879\n",
      "iter 300:\t Loss = 0.053227\n",
      "-----------------------------------------------\n",
      "Training epoch :  113\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079536\n",
      "iter  50:\t Loss = 0.079614\n",
      "iter 100:\t Loss = 0.040784\n",
      "iter 150:\t Loss = 0.061044\n",
      "iter 200:\t Loss = 0.073546\n",
      "iter 250:\t Loss = 0.058830\n",
      "iter 300:\t Loss = 0.052922\n",
      "-----------------------------------------------\n",
      "Training epoch :  114\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079437\n",
      "iter  50:\t Loss = 0.079515\n",
      "iter 100:\t Loss = 0.040796\n",
      "iter 150:\t Loss = 0.060999\n",
      "iter 200:\t Loss = 0.073304\n",
      "iter 250:\t Loss = 0.058782\n",
      "iter 300:\t Loss = 0.052619\n",
      "-----------------------------------------------\n",
      "Training epoch :  115\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079337\n",
      "iter  50:\t Loss = 0.079415\n",
      "iter 100:\t Loss = 0.040813\n",
      "iter 150:\t Loss = 0.060962\n",
      "iter 200:\t Loss = 0.073062\n",
      "iter 250:\t Loss = 0.058734\n",
      "iter 300:\t Loss = 0.052320\n",
      "-----------------------------------------------\n",
      "Training epoch :  116\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079237\n",
      "iter  50:\t Loss = 0.079314\n",
      "iter 100:\t Loss = 0.040835\n",
      "iter 150:\t Loss = 0.060934\n",
      "iter 200:\t Loss = 0.072821\n",
      "iter 250:\t Loss = 0.058686\n",
      "iter 300:\t Loss = 0.052025\n",
      "-----------------------------------------------\n",
      "Training epoch :  117\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079138\n",
      "iter  50:\t Loss = 0.079212\n",
      "iter 100:\t Loss = 0.040861\n",
      "iter 150:\t Loss = 0.060914\n",
      "iter 200:\t Loss = 0.072582\n",
      "iter 250:\t Loss = 0.058638\n",
      "iter 300:\t Loss = 0.051736\n",
      "-----------------------------------------------\n",
      "Training epoch :  118\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.079040\n",
      "iter  50:\t Loss = 0.079110\n",
      "iter 100:\t Loss = 0.040890\n",
      "iter 150:\t Loss = 0.060900\n",
      "iter 200:\t Loss = 0.072343\n",
      "iter 250:\t Loss = 0.058591\n",
      "iter 300:\t Loss = 0.051453\n",
      "-----------------------------------------------\n",
      "Training epoch :  119\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078943\n",
      "iter  50:\t Loss = 0.079008\n",
      "iter 100:\t Loss = 0.040923\n",
      "iter 150:\t Loss = 0.060893\n",
      "iter 200:\t Loss = 0.072107\n",
      "iter 250:\t Loss = 0.058545\n",
      "iter 300:\t Loss = 0.051177\n",
      "-----------------------------------------------\n",
      "Training epoch :  120\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078847\n",
      "iter  50:\t Loss = 0.078907\n",
      "iter 100:\t Loss = 0.040957\n",
      "iter 150:\t Loss = 0.060892\n",
      "iter 200:\t Loss = 0.071874\n",
      "iter 250:\t Loss = 0.058499\n",
      "iter 300:\t Loss = 0.050909\n",
      "-----------------------------------------------\n",
      "Training epoch :  121\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078754\n",
      "iter  50:\t Loss = 0.078805\n",
      "iter 100:\t Loss = 0.040992\n",
      "iter 150:\t Loss = 0.060895\n",
      "iter 200:\t Loss = 0.071643\n",
      "iter 250:\t Loss = 0.058453\n",
      "iter 300:\t Loss = 0.050649\n",
      "-----------------------------------------------\n",
      "Training epoch :  122\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078662\n",
      "iter  50:\t Loss = 0.078705\n",
      "iter 100:\t Loss = 0.041027\n",
      "iter 150:\t Loss = 0.060903\n",
      "iter 200:\t Loss = 0.071415\n",
      "iter 250:\t Loss = 0.058409\n",
      "iter 300:\t Loss = 0.050397\n",
      "-----------------------------------------------\n",
      "Training epoch :  123\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078573\n",
      "iter  50:\t Loss = 0.078605\n",
      "iter 100:\t Loss = 0.041062\n",
      "iter 150:\t Loss = 0.060915\n",
      "iter 200:\t Loss = 0.071191\n",
      "iter 250:\t Loss = 0.058365\n",
      "iter 300:\t Loss = 0.050154\n",
      "-----------------------------------------------\n",
      "Training epoch :  124\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078485\n",
      "iter  50:\t Loss = 0.078505\n",
      "iter 100:\t Loss = 0.041097\n",
      "iter 150:\t Loss = 0.060930\n",
      "iter 200:\t Loss = 0.070971\n",
      "iter 250:\t Loss = 0.058323\n",
      "iter 300:\t Loss = 0.049920\n",
      "-----------------------------------------------\n",
      "Training epoch :  125\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078398\n",
      "iter  50:\t Loss = 0.078405\n",
      "iter 100:\t Loss = 0.041130\n",
      "iter 150:\t Loss = 0.060948\n",
      "iter 200:\t Loss = 0.070756\n",
      "iter 250:\t Loss = 0.058281\n",
      "iter 300:\t Loss = 0.049694\n",
      "-----------------------------------------------\n",
      "Training epoch :  126\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078314\n",
      "iter  50:\t Loss = 0.078306\n",
      "iter 100:\t Loss = 0.041161\n",
      "iter 150:\t Loss = 0.060968\n",
      "iter 200:\t Loss = 0.070545\n",
      "iter 250:\t Loss = 0.058240\n",
      "iter 300:\t Loss = 0.049476\n",
      "-----------------------------------------------\n",
      "Training epoch :  127\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078231\n",
      "iter  50:\t Loss = 0.078207\n",
      "iter 100:\t Loss = 0.041190\n",
      "iter 150:\t Loss = 0.060989\n",
      "iter 200:\t Loss = 0.070339\n",
      "iter 250:\t Loss = 0.058200\n",
      "iter 300:\t Loss = 0.049268\n",
      "-----------------------------------------------\n",
      "Training epoch :  128\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078149\n",
      "iter  50:\t Loss = 0.078108\n",
      "iter 100:\t Loss = 0.041216\n",
      "iter 150:\t Loss = 0.061013\n",
      "iter 200:\t Loss = 0.070139\n",
      "iter 250:\t Loss = 0.058162\n",
      "iter 300:\t Loss = 0.049067\n",
      "-----------------------------------------------\n",
      "Training epoch :  129\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.078068\n",
      "iter  50:\t Loss = 0.078008\n",
      "iter 100:\t Loss = 0.041240\n",
      "iter 150:\t Loss = 0.061036\n",
      "iter 200:\t Loss = 0.069944\n",
      "iter 250:\t Loss = 0.058123\n",
      "iter 300:\t Loss = 0.048875\n",
      "-----------------------------------------------\n",
      "Training epoch :  130\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077988\n",
      "iter  50:\t Loss = 0.077908\n",
      "iter 100:\t Loss = 0.041261\n",
      "iter 150:\t Loss = 0.061061\n",
      "iter 200:\t Loss = 0.069754\n",
      "iter 250:\t Loss = 0.058086\n",
      "iter 300:\t Loss = 0.048691\n",
      "-----------------------------------------------\n",
      "Training epoch :  131\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077909\n",
      "iter  50:\t Loss = 0.077808\n",
      "iter 100:\t Loss = 0.041279\n",
      "iter 150:\t Loss = 0.061086\n",
      "iter 200:\t Loss = 0.069571\n",
      "iter 250:\t Loss = 0.058050\n",
      "iter 300:\t Loss = 0.048515\n",
      "-----------------------------------------------\n",
      "Training epoch :  132\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077830\n",
      "iter  50:\t Loss = 0.077707\n",
      "iter 100:\t Loss = 0.041294\n",
      "iter 150:\t Loss = 0.061111\n",
      "iter 200:\t Loss = 0.069394\n",
      "iter 250:\t Loss = 0.058014\n",
      "iter 300:\t Loss = 0.048346\n",
      "-----------------------------------------------\n",
      "Training epoch :  133\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077753\n",
      "iter  50:\t Loss = 0.077606\n",
      "iter 100:\t Loss = 0.041306\n",
      "iter 150:\t Loss = 0.061135\n",
      "iter 200:\t Loss = 0.069223\n",
      "iter 250:\t Loss = 0.057979\n",
      "iter 300:\t Loss = 0.048185\n",
      "-----------------------------------------------\n",
      "Training epoch :  134\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.077503\n",
      "iter 100:\t Loss = 0.041315\n",
      "iter 150:\t Loss = 0.061159\n",
      "iter 200:\t Loss = 0.069058\n",
      "iter 250:\t Loss = 0.057945\n",
      "iter 300:\t Loss = 0.048031\n",
      "-----------------------------------------------\n",
      "Training epoch :  135\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077600\n",
      "iter  50:\t Loss = 0.077401\n",
      "iter 100:\t Loss = 0.041322\n",
      "iter 150:\t Loss = 0.061183\n",
      "iter 200:\t Loss = 0.068899\n",
      "iter 250:\t Loss = 0.057911\n",
      "iter 300:\t Loss = 0.047885\n",
      "-----------------------------------------------\n",
      "Training epoch :  136\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077524\n",
      "iter  50:\t Loss = 0.077298\n",
      "iter 100:\t Loss = 0.041326\n",
      "iter 150:\t Loss = 0.061206\n",
      "iter 200:\t Loss = 0.068747\n",
      "iter 250:\t Loss = 0.057878\n",
      "iter 300:\t Loss = 0.047745\n",
      "-----------------------------------------------\n",
      "Training epoch :  137\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077450\n",
      "iter  50:\t Loss = 0.077194\n",
      "iter 100:\t Loss = 0.041327\n",
      "iter 150:\t Loss = 0.061229\n",
      "iter 200:\t Loss = 0.068601\n",
      "iter 250:\t Loss = 0.057845\n",
      "iter 300:\t Loss = 0.047611\n",
      "-----------------------------------------------\n",
      "Training epoch :  138\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077376\n",
      "iter  50:\t Loss = 0.077091\n",
      "iter 100:\t Loss = 0.041326\n",
      "iter 150:\t Loss = 0.061251\n",
      "iter 200:\t Loss = 0.068461\n",
      "iter 250:\t Loss = 0.057812\n",
      "iter 300:\t Loss = 0.047483\n",
      "-----------------------------------------------\n",
      "Training epoch :  139\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077304\n",
      "iter  50:\t Loss = 0.076987\n",
      "iter 100:\t Loss = 0.041323\n",
      "iter 150:\t Loss = 0.061272\n",
      "iter 200:\t Loss = 0.068327\n",
      "iter 250:\t Loss = 0.057780\n",
      "iter 300:\t Loss = 0.047362\n",
      "-----------------------------------------------\n",
      "Training epoch :  140\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077232\n",
      "iter  50:\t Loss = 0.076884\n",
      "iter 100:\t Loss = 0.041318\n",
      "iter 150:\t Loss = 0.061293\n",
      "iter 200:\t Loss = 0.068199\n",
      "iter 250:\t Loss = 0.057749\n",
      "iter 300:\t Loss = 0.047246\n",
      "-----------------------------------------------\n",
      "Training epoch :  141\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077162\n",
      "iter  50:\t Loss = 0.076781\n",
      "iter 100:\t Loss = 0.041310\n",
      "iter 150:\t Loss = 0.061313\n",
      "iter 200:\t Loss = 0.068077\n",
      "iter 250:\t Loss = 0.057717\n",
      "iter 300:\t Loss = 0.047136\n",
      "-----------------------------------------------\n",
      "Training epoch :  142\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077093\n",
      "iter  50:\t Loss = 0.076679\n",
      "iter 100:\t Loss = 0.041301\n",
      "iter 150:\t Loss = 0.061332\n",
      "iter 200:\t Loss = 0.067961\n",
      "iter 250:\t Loss = 0.057686\n",
      "iter 300:\t Loss = 0.047031\n",
      "-----------------------------------------------\n",
      "Training epoch :  143\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.077025\n",
      "iter  50:\t Loss = 0.076579\n",
      "iter 100:\t Loss = 0.041291\n",
      "iter 150:\t Loss = 0.061351\n",
      "iter 200:\t Loss = 0.067849\n",
      "iter 250:\t Loss = 0.057655\n",
      "iter 300:\t Loss = 0.046930\n",
      "-----------------------------------------------\n",
      "Training epoch :  144\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076958\n",
      "iter  50:\t Loss = 0.076479\n",
      "iter 100:\t Loss = 0.041278\n",
      "iter 150:\t Loss = 0.061370\n",
      "iter 200:\t Loss = 0.067743\n",
      "iter 250:\t Loss = 0.057624\n",
      "iter 300:\t Loss = 0.046834\n",
      "-----------------------------------------------\n",
      "Training epoch :  145\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076892\n",
      "iter  50:\t Loss = 0.076381\n",
      "iter 100:\t Loss = 0.041264\n",
      "iter 150:\t Loss = 0.061388\n",
      "iter 200:\t Loss = 0.067642\n",
      "iter 250:\t Loss = 0.057593\n",
      "iter 300:\t Loss = 0.046743\n",
      "-----------------------------------------------\n",
      "Training epoch :  146\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076828\n",
      "iter  50:\t Loss = 0.076285\n",
      "iter 100:\t Loss = 0.041249\n",
      "iter 150:\t Loss = 0.061406\n",
      "iter 200:\t Loss = 0.067545\n",
      "iter 250:\t Loss = 0.057562\n",
      "iter 300:\t Loss = 0.046656\n",
      "-----------------------------------------------\n",
      "Training epoch :  147\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076765\n",
      "iter  50:\t Loss = 0.076191\n",
      "iter 100:\t Loss = 0.041232\n",
      "iter 150:\t Loss = 0.061424\n",
      "iter 200:\t Loss = 0.067453\n",
      "iter 250:\t Loss = 0.057531\n",
      "iter 300:\t Loss = 0.046572\n",
      "-----------------------------------------------\n",
      "Training epoch :  148\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076703\n",
      "iter  50:\t Loss = 0.076099\n",
      "iter 100:\t Loss = 0.041215\n",
      "iter 150:\t Loss = 0.061441\n",
      "iter 200:\t Loss = 0.067364\n",
      "iter 250:\t Loss = 0.057501\n",
      "iter 300:\t Loss = 0.046493\n",
      "-----------------------------------------------\n",
      "Training epoch :  149\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076642\n",
      "iter  50:\t Loss = 0.076009\n",
      "iter 100:\t Loss = 0.041196\n",
      "iter 150:\t Loss = 0.061459\n",
      "iter 200:\t Loss = 0.067280\n",
      "iter 250:\t Loss = 0.057470\n",
      "iter 300:\t Loss = 0.046417\n",
      "-----------------------------------------------\n",
      "Training epoch :  150\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076583\n",
      "iter  50:\t Loss = 0.075922\n",
      "iter 100:\t Loss = 0.041176\n",
      "iter 150:\t Loss = 0.061476\n",
      "iter 200:\t Loss = 0.067199\n",
      "iter 250:\t Loss = 0.057439\n",
      "iter 300:\t Loss = 0.046344\n",
      "-----------------------------------------------\n",
      "Training epoch :  151\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076524\n",
      "iter  50:\t Loss = 0.075837\n",
      "iter 100:\t Loss = 0.041156\n",
      "iter 150:\t Loss = 0.061493\n",
      "iter 200:\t Loss = 0.067121\n",
      "iter 250:\t Loss = 0.057408\n",
      "iter 300:\t Loss = 0.046274\n",
      "-----------------------------------------------\n",
      "Training epoch :  152\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076467\n",
      "iter  50:\t Loss = 0.075754\n",
      "iter 100:\t Loss = 0.041134\n",
      "iter 150:\t Loss = 0.061510\n",
      "iter 200:\t Loss = 0.067047\n",
      "iter 250:\t Loss = 0.057377\n",
      "iter 300:\t Loss = 0.046206\n",
      "-----------------------------------------------\n",
      "Training epoch :  153\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076411\n",
      "iter  50:\t Loss = 0.075675\n",
      "iter 100:\t Loss = 0.041112\n",
      "iter 150:\t Loss = 0.061527\n",
      "iter 200:\t Loss = 0.066975\n",
      "iter 250:\t Loss = 0.057346\n",
      "iter 300:\t Loss = 0.046142\n",
      "-----------------------------------------------\n",
      "Training epoch :  154\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076356\n",
      "iter  50:\t Loss = 0.075598\n",
      "iter 100:\t Loss = 0.041089\n",
      "iter 150:\t Loss = 0.061544\n",
      "iter 200:\t Loss = 0.066906\n",
      "iter 250:\t Loss = 0.057314\n",
      "iter 300:\t Loss = 0.046080\n",
      "-----------------------------------------------\n",
      "Training epoch :  155\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076302\n",
      "iter  50:\t Loss = 0.075523\n",
      "iter 100:\t Loss = 0.041065\n",
      "iter 150:\t Loss = 0.061561\n",
      "iter 200:\t Loss = 0.066838\n",
      "iter 250:\t Loss = 0.057283\n",
      "iter 300:\t Loss = 0.046020\n",
      "-----------------------------------------------\n",
      "Training epoch :  156\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076249\n",
      "iter  50:\t Loss = 0.075451\n",
      "iter 100:\t Loss = 0.041041\n",
      "iter 150:\t Loss = 0.061578\n",
      "iter 200:\t Loss = 0.066773\n",
      "iter 250:\t Loss = 0.057251\n",
      "iter 300:\t Loss = 0.045962\n",
      "-----------------------------------------------\n",
      "Training epoch :  157\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076196\n",
      "iter  50:\t Loss = 0.075382\n",
      "iter 100:\t Loss = 0.041016\n",
      "iter 150:\t Loss = 0.061595\n",
      "iter 200:\t Loss = 0.066710\n",
      "iter 250:\t Loss = 0.057219\n",
      "iter 300:\t Loss = 0.045906\n",
      "-----------------------------------------------\n",
      "Training epoch :  158\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076145\n",
      "iter  50:\t Loss = 0.075315\n",
      "iter 100:\t Loss = 0.040990\n",
      "iter 150:\t Loss = 0.061612\n",
      "iter 200:\t Loss = 0.066648\n",
      "iter 250:\t Loss = 0.057186\n",
      "iter 300:\t Loss = 0.045852\n",
      "-----------------------------------------------\n",
      "Training epoch :  159\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076094\n",
      "iter  50:\t Loss = 0.075251\n",
      "iter 100:\t Loss = 0.040964\n",
      "iter 150:\t Loss = 0.061628\n",
      "iter 200:\t Loss = 0.066588\n",
      "iter 250:\t Loss = 0.057154\n",
      "iter 300:\t Loss = 0.045800\n",
      "-----------------------------------------------\n",
      "Training epoch :  160\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.076043\n",
      "iter  50:\t Loss = 0.075189\n",
      "iter 100:\t Loss = 0.040937\n",
      "iter 150:\t Loss = 0.061645\n",
      "iter 200:\t Loss = 0.066529\n",
      "iter 250:\t Loss = 0.057120\n",
      "iter 300:\t Loss = 0.045749\n",
      "-----------------------------------------------\n",
      "Training epoch :  161\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.075129\n",
      "iter 100:\t Loss = 0.040910\n",
      "iter 150:\t Loss = 0.061661\n",
      "iter 200:\t Loss = 0.066471\n",
      "iter 250:\t Loss = 0.057087\n",
      "iter 300:\t Loss = 0.045700\n",
      "-----------------------------------------------\n",
      "Training epoch :  162\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075944\n",
      "iter  50:\t Loss = 0.075072\n",
      "iter 100:\t Loss = 0.040883\n",
      "iter 150:\t Loss = 0.061678\n",
      "iter 200:\t Loss = 0.066413\n",
      "iter 250:\t Loss = 0.057053\n",
      "iter 300:\t Loss = 0.045652\n",
      "-----------------------------------------------\n",
      "Training epoch :  163\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075895\n",
      "iter  50:\t Loss = 0.075016\n",
      "iter 100:\t Loss = 0.040855\n",
      "iter 150:\t Loss = 0.061694\n",
      "iter 200:\t Loss = 0.066357\n",
      "iter 250:\t Loss = 0.057019\n",
      "iter 300:\t Loss = 0.045605\n",
      "-----------------------------------------------\n",
      "Training epoch :  164\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075847\n",
      "iter  50:\t Loss = 0.074962\n",
      "iter 100:\t Loss = 0.040827\n",
      "iter 150:\t Loss = 0.061710\n",
      "iter 200:\t Loss = 0.066301\n",
      "iter 250:\t Loss = 0.056985\n",
      "iter 300:\t Loss = 0.045559\n",
      "-----------------------------------------------\n",
      "Training epoch :  165\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075799\n",
      "iter  50:\t Loss = 0.074910\n",
      "iter 100:\t Loss = 0.040798\n",
      "iter 150:\t Loss = 0.061726\n",
      "iter 200:\t Loss = 0.066245\n",
      "iter 250:\t Loss = 0.056950\n",
      "iter 300:\t Loss = 0.045515\n",
      "-----------------------------------------------\n",
      "Training epoch :  166\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075751\n",
      "iter  50:\t Loss = 0.074859\n",
      "iter 100:\t Loss = 0.040770\n",
      "iter 150:\t Loss = 0.061742\n",
      "iter 200:\t Loss = 0.066190\n",
      "iter 250:\t Loss = 0.056915\n",
      "iter 300:\t Loss = 0.045471\n",
      "-----------------------------------------------\n",
      "Training epoch :  167\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075704\n",
      "iter  50:\t Loss = 0.074810\n",
      "iter 100:\t Loss = 0.040741\n",
      "iter 150:\t Loss = 0.061757\n",
      "iter 200:\t Loss = 0.066135\n",
      "iter 250:\t Loss = 0.056879\n",
      "iter 300:\t Loss = 0.045428\n",
      "-----------------------------------------------\n",
      "Training epoch :  168\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075657\n",
      "iter  50:\t Loss = 0.074762\n",
      "iter 100:\t Loss = 0.040712\n",
      "iter 150:\t Loss = 0.061773\n",
      "iter 200:\t Loss = 0.066080\n",
      "iter 250:\t Loss = 0.056843\n",
      "iter 300:\t Loss = 0.045386\n",
      "-----------------------------------------------\n",
      "Training epoch :  169\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075610\n",
      "iter  50:\t Loss = 0.074716\n",
      "iter 100:\t Loss = 0.040682\n",
      "iter 150:\t Loss = 0.061788\n",
      "iter 200:\t Loss = 0.066025\n",
      "iter 250:\t Loss = 0.056807\n",
      "iter 300:\t Loss = 0.045345\n",
      "-----------------------------------------------\n",
      "Training epoch :  170\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075563\n",
      "iter  50:\t Loss = 0.074670\n",
      "iter 100:\t Loss = 0.040653\n",
      "iter 150:\t Loss = 0.061803\n",
      "iter 200:\t Loss = 0.065970\n",
      "iter 250:\t Loss = 0.056770\n",
      "iter 300:\t Loss = 0.045304\n",
      "-----------------------------------------------\n",
      "Training epoch :  171\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075516\n",
      "iter  50:\t Loss = 0.074625\n",
      "iter 100:\t Loss = 0.040624\n",
      "iter 150:\t Loss = 0.061817\n",
      "iter 200:\t Loss = 0.065915\n",
      "iter 250:\t Loss = 0.056732\n",
      "iter 300:\t Loss = 0.045263\n",
      "-----------------------------------------------\n",
      "Training epoch :  172\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075470\n",
      "iter  50:\t Loss = 0.074581\n",
      "iter 100:\t Loss = 0.040594\n",
      "iter 150:\t Loss = 0.061831\n",
      "iter 200:\t Loss = 0.065860\n",
      "iter 250:\t Loss = 0.056694\n",
      "iter 300:\t Loss = 0.045224\n",
      "-----------------------------------------------\n",
      "Training epoch :  173\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075423\n",
      "iter  50:\t Loss = 0.074538\n",
      "iter 100:\t Loss = 0.040565\n",
      "iter 150:\t Loss = 0.061845\n",
      "iter 200:\t Loss = 0.065804\n",
      "iter 250:\t Loss = 0.056656\n",
      "iter 300:\t Loss = 0.045184\n",
      "-----------------------------------------------\n",
      "Training epoch :  174\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075377\n",
      "iter  50:\t Loss = 0.074495\n",
      "iter 100:\t Loss = 0.040535\n",
      "iter 150:\t Loss = 0.061859\n",
      "iter 200:\t Loss = 0.065748\n",
      "iter 250:\t Loss = 0.056618\n",
      "iter 300:\t Loss = 0.045145\n",
      "-----------------------------------------------\n",
      "Training epoch :  175\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075331\n",
      "iter  50:\t Loss = 0.074453\n",
      "iter 100:\t Loss = 0.040506\n",
      "iter 150:\t Loss = 0.061872\n",
      "iter 200:\t Loss = 0.065692\n",
      "iter 250:\t Loss = 0.056579\n",
      "iter 300:\t Loss = 0.045106\n",
      "-----------------------------------------------\n",
      "Training epoch :  176\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075284\n",
      "iter  50:\t Loss = 0.074411\n",
      "iter 100:\t Loss = 0.040477\n",
      "iter 150:\t Loss = 0.061884\n",
      "iter 200:\t Loss = 0.065635\n",
      "iter 250:\t Loss = 0.056539\n",
      "iter 300:\t Loss = 0.045068\n",
      "-----------------------------------------------\n",
      "Training epoch :  177\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075238\n",
      "iter  50:\t Loss = 0.074369\n",
      "iter 100:\t Loss = 0.040448\n",
      "iter 150:\t Loss = 0.061897\n",
      "iter 200:\t Loss = 0.065578\n",
      "iter 250:\t Loss = 0.056499\n",
      "iter 300:\t Loss = 0.045029\n",
      "-----------------------------------------------\n",
      "Training epoch :  178\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075191\n",
      "iter  50:\t Loss = 0.074328\n",
      "iter 100:\t Loss = 0.040419\n",
      "iter 150:\t Loss = 0.061908\n",
      "iter 200:\t Loss = 0.065521\n",
      "iter 250:\t Loss = 0.056459\n",
      "iter 300:\t Loss = 0.044991\n",
      "-----------------------------------------------\n",
      "Training epoch :  179\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075145\n",
      "iter  50:\t Loss = 0.074286\n",
      "iter 100:\t Loss = 0.040390\n",
      "iter 150:\t Loss = 0.061919\n",
      "iter 200:\t Loss = 0.065463\n",
      "iter 250:\t Loss = 0.056419\n",
      "iter 300:\t Loss = 0.044953\n",
      "-----------------------------------------------\n",
      "Training epoch :  180\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075098\n",
      "iter  50:\t Loss = 0.074245\n",
      "iter 100:\t Loss = 0.040362\n",
      "iter 150:\t Loss = 0.061930\n",
      "iter 200:\t Loss = 0.065405\n",
      "iter 250:\t Loss = 0.056378\n",
      "iter 300:\t Loss = 0.044915\n",
      "-----------------------------------------------\n",
      "Training epoch :  181\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075050\n",
      "iter  50:\t Loss = 0.074204\n",
      "iter 100:\t Loss = 0.040334\n",
      "iter 150:\t Loss = 0.061940\n",
      "iter 200:\t Loss = 0.065346\n",
      "iter 250:\t Loss = 0.056337\n",
      "iter 300:\t Loss = 0.044877\n",
      "-----------------------------------------------\n",
      "Training epoch :  182\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.075003\n",
      "iter  50:\t Loss = 0.074164\n",
      "iter 100:\t Loss = 0.040307\n",
      "iter 150:\t Loss = 0.061949\n",
      "iter 200:\t Loss = 0.065287\n",
      "iter 250:\t Loss = 0.056295\n",
      "iter 300:\t Loss = 0.044839\n",
      "-----------------------------------------------\n",
      "Training epoch :  183\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074955\n",
      "iter  50:\t Loss = 0.074123\n",
      "iter 100:\t Loss = 0.040280\n",
      "iter 150:\t Loss = 0.061958\n",
      "iter 200:\t Loss = 0.065227\n",
      "iter 250:\t Loss = 0.056253\n",
      "iter 300:\t Loss = 0.044800\n",
      "-----------------------------------------------\n",
      "Training epoch :  184\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074906\n",
      "iter  50:\t Loss = 0.074083\n",
      "iter 100:\t Loss = 0.040253\n",
      "iter 150:\t Loss = 0.061966\n",
      "iter 200:\t Loss = 0.065167\n",
      "iter 250:\t Loss = 0.056212\n",
      "iter 300:\t Loss = 0.044762\n",
      "-----------------------------------------------\n",
      "Training epoch :  185\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074857\n",
      "iter  50:\t Loss = 0.074043\n",
      "iter 100:\t Loss = 0.040226\n",
      "iter 150:\t Loss = 0.061973\n",
      "iter 200:\t Loss = 0.065106\n",
      "iter 250:\t Loss = 0.056170\n",
      "iter 300:\t Loss = 0.044723\n",
      "-----------------------------------------------\n",
      "Training epoch :  186\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074807\n",
      "iter  50:\t Loss = 0.074003\n",
      "iter 100:\t Loss = 0.040200\n",
      "iter 150:\t Loss = 0.061979\n",
      "iter 200:\t Loss = 0.065045\n",
      "iter 250:\t Loss = 0.056127\n",
      "iter 300:\t Loss = 0.044685\n",
      "-----------------------------------------------\n",
      "Training epoch :  187\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074756\n",
      "iter  50:\t Loss = 0.073964\n",
      "iter 100:\t Loss = 0.040175\n",
      "iter 150:\t Loss = 0.061985\n",
      "iter 200:\t Loss = 0.064984\n",
      "iter 250:\t Loss = 0.056085\n",
      "iter 300:\t Loss = 0.044646\n",
      "-----------------------------------------------\n",
      "Training epoch :  188\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.073925\n",
      "iter 100:\t Loss = 0.040149\n",
      "iter 150:\t Loss = 0.061990\n",
      "iter 200:\t Loss = 0.064922\n",
      "iter 250:\t Loss = 0.056043\n",
      "iter 300:\t Loss = 0.044607\n",
      "-----------------------------------------------\n",
      "Training epoch :  189\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074652\n",
      "iter  50:\t Loss = 0.073887\n",
      "iter 100:\t Loss = 0.040124\n",
      "iter 150:\t Loss = 0.061995\n",
      "iter 200:\t Loss = 0.064860\n",
      "iter 250:\t Loss = 0.056000\n",
      "iter 300:\t Loss = 0.044567\n",
      "-----------------------------------------------\n",
      "Training epoch :  190\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074599\n",
      "iter  50:\t Loss = 0.073849\n",
      "iter 100:\t Loss = 0.040100\n",
      "iter 150:\t Loss = 0.061998\n",
      "iter 200:\t Loss = 0.064797\n",
      "iter 250:\t Loss = 0.055958\n",
      "iter 300:\t Loss = 0.044528\n",
      "-----------------------------------------------\n",
      "Training epoch :  191\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074544\n",
      "iter  50:\t Loss = 0.073813\n",
      "iter 100:\t Loss = 0.040076\n",
      "iter 150:\t Loss = 0.062001\n",
      "iter 200:\t Loss = 0.064735\n",
      "iter 250:\t Loss = 0.055916\n",
      "iter 300:\t Loss = 0.044488\n",
      "-----------------------------------------------\n",
      "Training epoch :  192\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074489\n",
      "iter  50:\t Loss = 0.073777\n",
      "iter 100:\t Loss = 0.040051\n",
      "iter 150:\t Loss = 0.062003\n",
      "iter 200:\t Loss = 0.064672\n",
      "iter 250:\t Loss = 0.055874\n",
      "iter 300:\t Loss = 0.044449\n",
      "-----------------------------------------------\n",
      "Training epoch :  193\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074432\n",
      "iter  50:\t Loss = 0.073742\n",
      "iter 100:\t Loss = 0.040027\n",
      "iter 150:\t Loss = 0.062005\n",
      "iter 200:\t Loss = 0.064610\n",
      "iter 250:\t Loss = 0.055832\n",
      "iter 300:\t Loss = 0.044409\n",
      "-----------------------------------------------\n",
      "Training epoch :  194\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074375\n",
      "iter  50:\t Loss = 0.073708\n",
      "iter 100:\t Loss = 0.040003\n",
      "iter 150:\t Loss = 0.062006\n",
      "iter 200:\t Loss = 0.064547\n",
      "iter 250:\t Loss = 0.055790\n",
      "iter 300:\t Loss = 0.044369\n",
      "-----------------------------------------------\n",
      "Training epoch :  195\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074316\n",
      "iter  50:\t Loss = 0.073675\n",
      "iter 100:\t Loss = 0.039979\n",
      "iter 150:\t Loss = 0.062007\n",
      "iter 200:\t Loss = 0.064484\n",
      "iter 250:\t Loss = 0.055748\n",
      "iter 300:\t Loss = 0.044329\n",
      "-----------------------------------------------\n",
      "Training epoch :  196\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074256\n",
      "iter  50:\t Loss = 0.073644\n",
      "iter 100:\t Loss = 0.039955\n",
      "iter 150:\t Loss = 0.062007\n",
      "iter 200:\t Loss = 0.064422\n",
      "iter 250:\t Loss = 0.055707\n",
      "iter 300:\t Loss = 0.044288\n",
      "-----------------------------------------------\n",
      "Training epoch :  197\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074196\n",
      "iter  50:\t Loss = 0.073613\n",
      "iter 100:\t Loss = 0.039931\n",
      "iter 150:\t Loss = 0.062007\n",
      "iter 200:\t Loss = 0.064359\n",
      "iter 250:\t Loss = 0.055666\n",
      "iter 300:\t Loss = 0.044248\n",
      "-----------------------------------------------\n",
      "Training epoch :  198\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074134\n",
      "iter  50:\t Loss = 0.073584\n",
      "iter 100:\t Loss = 0.039906\n",
      "iter 150:\t Loss = 0.062006\n",
      "iter 200:\t Loss = 0.064297\n",
      "iter 250:\t Loss = 0.055626\n",
      "iter 300:\t Loss = 0.044208\n",
      "-----------------------------------------------\n",
      "Training epoch :  199\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074072\n",
      "iter  50:\t Loss = 0.073555\n",
      "iter 100:\t Loss = 0.039882\n",
      "iter 150:\t Loss = 0.062005\n",
      "iter 200:\t Loss = 0.064235\n",
      "iter 250:\t Loss = 0.055585\n",
      "iter 300:\t Loss = 0.044168\n",
      "-----------------------------------------------\n",
      "Training epoch :  200\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.074008\n",
      "iter  50:\t Loss = 0.073528\n",
      "iter 100:\t Loss = 0.039857\n",
      "iter 150:\t Loss = 0.062004\n",
      "iter 200:\t Loss = 0.064174\n",
      "iter 250:\t Loss = 0.055546\n",
      "iter 300:\t Loss = 0.044128\n",
      "-----------------------------------------------\n",
      "Training epoch :  201\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073945\n",
      "iter  50:\t Loss = 0.073501\n",
      "iter 100:\t Loss = 0.039831\n",
      "iter 150:\t Loss = 0.062002\n",
      "iter 200:\t Loss = 0.064112\n",
      "iter 250:\t Loss = 0.055506\n",
      "iter 300:\t Loss = 0.044088\n",
      "-----------------------------------------------\n",
      "Training epoch :  202\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073880\n",
      "iter  50:\t Loss = 0.073476\n",
      "iter 100:\t Loss = 0.039805\n",
      "iter 150:\t Loss = 0.062000\n",
      "iter 200:\t Loss = 0.064051\n",
      "iter 250:\t Loss = 0.055467\n",
      "iter 300:\t Loss = 0.044047\n",
      "-----------------------------------------------\n",
      "Training epoch :  203\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073815\n",
      "iter  50:\t Loss = 0.073452\n",
      "iter 100:\t Loss = 0.039779\n",
      "iter 150:\t Loss = 0.061998\n",
      "iter 200:\t Loss = 0.063990\n",
      "iter 250:\t Loss = 0.055429\n",
      "iter 300:\t Loss = 0.044008\n",
      "-----------------------------------------------\n",
      "Training epoch :  204\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073750\n",
      "iter  50:\t Loss = 0.073428\n",
      "iter 100:\t Loss = 0.039752\n",
      "iter 150:\t Loss = 0.061996\n",
      "iter 200:\t Loss = 0.063930\n",
      "iter 250:\t Loss = 0.055391\n",
      "iter 300:\t Loss = 0.043968\n",
      "-----------------------------------------------\n",
      "Training epoch :  205\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073684\n",
      "iter  50:\t Loss = 0.073405\n",
      "iter 100:\t Loss = 0.039724\n",
      "iter 150:\t Loss = 0.061994\n",
      "iter 200:\t Loss = 0.063871\n",
      "iter 250:\t Loss = 0.055353\n",
      "iter 300:\t Loss = 0.043928\n",
      "-----------------------------------------------\n",
      "Training epoch :  206\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073618\n",
      "iter  50:\t Loss = 0.073383\n",
      "iter 100:\t Loss = 0.039697\n",
      "iter 150:\t Loss = 0.061991\n",
      "iter 200:\t Loss = 0.063812\n",
      "iter 250:\t Loss = 0.055316\n",
      "iter 300:\t Loss = 0.043888\n",
      "-----------------------------------------------\n",
      "Training epoch :  207\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073551\n",
      "iter  50:\t Loss = 0.073361\n",
      "iter 100:\t Loss = 0.039668\n",
      "iter 150:\t Loss = 0.061989\n",
      "iter 200:\t Loss = 0.063753\n",
      "iter 250:\t Loss = 0.055280\n",
      "iter 300:\t Loss = 0.043849\n",
      "-----------------------------------------------\n",
      "Training epoch :  208\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073484\n",
      "iter  50:\t Loss = 0.073340\n",
      "iter 100:\t Loss = 0.039639\n",
      "iter 150:\t Loss = 0.061986\n",
      "iter 200:\t Loss = 0.063695\n",
      "iter 250:\t Loss = 0.055244\n",
      "iter 300:\t Loss = 0.043810\n",
      "-----------------------------------------------\n",
      "Training epoch :  209\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073417\n",
      "iter  50:\t Loss = 0.073319\n",
      "iter 100:\t Loss = 0.039610\n",
      "iter 150:\t Loss = 0.061984\n",
      "iter 200:\t Loss = 0.063637\n",
      "iter 250:\t Loss = 0.055208\n",
      "iter 300:\t Loss = 0.043770\n",
      "-----------------------------------------------\n",
      "Training epoch :  210\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073350\n",
      "iter  50:\t Loss = 0.073299\n",
      "iter 100:\t Loss = 0.039580\n",
      "iter 150:\t Loss = 0.061981\n",
      "iter 200:\t Loss = 0.063580\n",
      "iter 250:\t Loss = 0.055173\n",
      "iter 300:\t Loss = 0.043731\n",
      "-----------------------------------------------\n",
      "Training epoch :  211\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073283\n",
      "iter  50:\t Loss = 0.073279\n",
      "iter 100:\t Loss = 0.039549\n",
      "iter 150:\t Loss = 0.061978\n",
      "iter 200:\t Loss = 0.063524\n",
      "iter 250:\t Loss = 0.055139\n",
      "iter 300:\t Loss = 0.043693\n",
      "-----------------------------------------------\n",
      "Training epoch :  212\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073215\n",
      "iter  50:\t Loss = 0.073259\n",
      "iter 100:\t Loss = 0.039518\n",
      "iter 150:\t Loss = 0.061975\n",
      "iter 200:\t Loss = 0.063468\n",
      "iter 250:\t Loss = 0.055105\n",
      "iter 300:\t Loss = 0.043654\n",
      "-----------------------------------------------\n",
      "Training epoch :  213\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073148\n",
      "iter  50:\t Loss = 0.073239\n",
      "iter 100:\t Loss = 0.039486\n",
      "iter 150:\t Loss = 0.061972\n",
      "iter 200:\t Loss = 0.063413\n",
      "iter 250:\t Loss = 0.055071\n",
      "iter 300:\t Loss = 0.043616\n",
      "-----------------------------------------------\n",
      "Training epoch :  214\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073080\n",
      "iter  50:\t Loss = 0.073220\n",
      "iter 100:\t Loss = 0.039454\n",
      "iter 150:\t Loss = 0.061969\n",
      "iter 200:\t Loss = 0.063358\n",
      "iter 250:\t Loss = 0.055038\n",
      "iter 300:\t Loss = 0.043578\n",
      "-----------------------------------------------\n",
      "Training epoch :  215\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.073013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.073200\n",
      "iter 100:\t Loss = 0.039422\n",
      "iter 150:\t Loss = 0.061967\n",
      "iter 200:\t Loss = 0.063304\n",
      "iter 250:\t Loss = 0.055006\n",
      "iter 300:\t Loss = 0.043540\n",
      "-----------------------------------------------\n",
      "Training epoch :  216\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072945\n",
      "iter  50:\t Loss = 0.073180\n",
      "iter 100:\t Loss = 0.039389\n",
      "iter 150:\t Loss = 0.061963\n",
      "iter 200:\t Loss = 0.063250\n",
      "iter 250:\t Loss = 0.054973\n",
      "iter 300:\t Loss = 0.043502\n",
      "-----------------------------------------------\n",
      "Training epoch :  217\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072877\n",
      "iter  50:\t Loss = 0.073161\n",
      "iter 100:\t Loss = 0.039356\n",
      "iter 150:\t Loss = 0.061961\n",
      "iter 200:\t Loss = 0.063197\n",
      "iter 250:\t Loss = 0.054942\n",
      "iter 300:\t Loss = 0.043465\n",
      "-----------------------------------------------\n",
      "Training epoch :  218\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072809\n",
      "iter  50:\t Loss = 0.073141\n",
      "iter 100:\t Loss = 0.039322\n",
      "iter 150:\t Loss = 0.061957\n",
      "iter 200:\t Loss = 0.063145\n",
      "iter 250:\t Loss = 0.054910\n",
      "iter 300:\t Loss = 0.043427\n",
      "-----------------------------------------------\n",
      "Training epoch :  219\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072741\n",
      "iter  50:\t Loss = 0.073122\n",
      "iter 100:\t Loss = 0.039288\n",
      "iter 150:\t Loss = 0.061954\n",
      "iter 200:\t Loss = 0.063093\n",
      "iter 250:\t Loss = 0.054879\n",
      "iter 300:\t Loss = 0.043390\n",
      "-----------------------------------------------\n",
      "Training epoch :  220\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072673\n",
      "iter  50:\t Loss = 0.073102\n",
      "iter 100:\t Loss = 0.039254\n",
      "iter 150:\t Loss = 0.061951\n",
      "iter 200:\t Loss = 0.063041\n",
      "iter 250:\t Loss = 0.054849\n",
      "iter 300:\t Loss = 0.043354\n",
      "-----------------------------------------------\n",
      "Training epoch :  221\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072606\n",
      "iter  50:\t Loss = 0.073082\n",
      "iter 100:\t Loss = 0.039219\n",
      "iter 150:\t Loss = 0.061948\n",
      "iter 200:\t Loss = 0.062990\n",
      "iter 250:\t Loss = 0.054819\n",
      "iter 300:\t Loss = 0.043317\n",
      "-----------------------------------------------\n",
      "Training epoch :  222\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072538\n",
      "iter  50:\t Loss = 0.073061\n",
      "iter 100:\t Loss = 0.039184\n",
      "iter 150:\t Loss = 0.061945\n",
      "iter 200:\t Loss = 0.062939\n",
      "iter 250:\t Loss = 0.054789\n",
      "iter 300:\t Loss = 0.043281\n",
      "-----------------------------------------------\n",
      "Training epoch :  223\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072469\n",
      "iter  50:\t Loss = 0.073041\n",
      "iter 100:\t Loss = 0.039149\n",
      "iter 150:\t Loss = 0.061942\n",
      "iter 200:\t Loss = 0.062889\n",
      "iter 250:\t Loss = 0.054759\n",
      "iter 300:\t Loss = 0.043245\n",
      "-----------------------------------------------\n",
      "Training epoch :  224\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072401\n",
      "iter  50:\t Loss = 0.073020\n",
      "iter 100:\t Loss = 0.039113\n",
      "iter 150:\t Loss = 0.061939\n",
      "iter 200:\t Loss = 0.062840\n",
      "iter 250:\t Loss = 0.054730\n",
      "iter 300:\t Loss = 0.043209\n",
      "-----------------------------------------------\n",
      "Training epoch :  225\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072333\n",
      "iter  50:\t Loss = 0.072999\n",
      "iter 100:\t Loss = 0.039077\n",
      "iter 150:\t Loss = 0.061936\n",
      "iter 200:\t Loss = 0.062790\n",
      "iter 250:\t Loss = 0.054701\n",
      "iter 300:\t Loss = 0.043174\n",
      "-----------------------------------------------\n",
      "Training epoch :  226\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072264\n",
      "iter  50:\t Loss = 0.072977\n",
      "iter 100:\t Loss = 0.039041\n",
      "iter 150:\t Loss = 0.061932\n",
      "iter 200:\t Loss = 0.062742\n",
      "iter 250:\t Loss = 0.054672\n",
      "iter 300:\t Loss = 0.043138\n",
      "-----------------------------------------------\n",
      "Training epoch :  227\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072196\n",
      "iter  50:\t Loss = 0.072955\n",
      "iter 100:\t Loss = 0.039005\n",
      "iter 150:\t Loss = 0.061929\n",
      "iter 200:\t Loss = 0.062693\n",
      "iter 250:\t Loss = 0.054644\n",
      "iter 300:\t Loss = 0.043104\n",
      "-----------------------------------------------\n",
      "Training epoch :  228\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072127\n",
      "iter  50:\t Loss = 0.072933\n",
      "iter 100:\t Loss = 0.038968\n",
      "iter 150:\t Loss = 0.061926\n",
      "iter 200:\t Loss = 0.062645\n",
      "iter 250:\t Loss = 0.054616\n",
      "iter 300:\t Loss = 0.043069\n",
      "-----------------------------------------------\n",
      "Training epoch :  229\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.072058\n",
      "iter  50:\t Loss = 0.072911\n",
      "iter 100:\t Loss = 0.038931\n",
      "iter 150:\t Loss = 0.061923\n",
      "iter 200:\t Loss = 0.062598\n",
      "iter 250:\t Loss = 0.054588\n",
      "iter 300:\t Loss = 0.043035\n",
      "-----------------------------------------------\n",
      "Training epoch :  230\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071989\n",
      "iter  50:\t Loss = 0.072888\n",
      "iter 100:\t Loss = 0.038894\n",
      "iter 150:\t Loss = 0.061920\n",
      "iter 200:\t Loss = 0.062550\n",
      "iter 250:\t Loss = 0.054560\n",
      "iter 300:\t Loss = 0.043000\n",
      "-----------------------------------------------\n",
      "Training epoch :  231\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071920\n",
      "iter  50:\t Loss = 0.072865\n",
      "iter 100:\t Loss = 0.038857\n",
      "iter 150:\t Loss = 0.061916\n",
      "iter 200:\t Loss = 0.062503\n",
      "iter 250:\t Loss = 0.054533\n",
      "iter 300:\t Loss = 0.042967\n",
      "-----------------------------------------------\n",
      "Training epoch :  232\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071851\n",
      "iter  50:\t Loss = 0.072841\n",
      "iter 100:\t Loss = 0.038820\n",
      "iter 150:\t Loss = 0.061913\n",
      "iter 200:\t Loss = 0.062457\n",
      "iter 250:\t Loss = 0.054506\n",
      "iter 300:\t Loss = 0.042933\n",
      "-----------------------------------------------\n",
      "Training epoch :  233\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071781\n",
      "iter  50:\t Loss = 0.072817\n",
      "iter 100:\t Loss = 0.038782\n",
      "iter 150:\t Loss = 0.061909\n",
      "iter 200:\t Loss = 0.062410\n",
      "iter 250:\t Loss = 0.054479\n",
      "iter 300:\t Loss = 0.042900\n",
      "-----------------------------------------------\n",
      "Training epoch :  234\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071711\n",
      "iter  50:\t Loss = 0.072793\n",
      "iter 100:\t Loss = 0.038744\n",
      "iter 150:\t Loss = 0.061906\n",
      "iter 200:\t Loss = 0.062364\n",
      "iter 250:\t Loss = 0.054452\n",
      "iter 300:\t Loss = 0.042867\n",
      "-----------------------------------------------\n",
      "Training epoch :  235\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071641\n",
      "iter  50:\t Loss = 0.072769\n",
      "iter 100:\t Loss = 0.038706\n",
      "iter 150:\t Loss = 0.061903\n",
      "iter 200:\t Loss = 0.062319\n",
      "iter 250:\t Loss = 0.054425\n",
      "iter 300:\t Loss = 0.042834\n",
      "-----------------------------------------------\n",
      "Training epoch :  236\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071571\n",
      "iter  50:\t Loss = 0.072744\n",
      "iter 100:\t Loss = 0.038668\n",
      "iter 150:\t Loss = 0.061899\n",
      "iter 200:\t Loss = 0.062274\n",
      "iter 250:\t Loss = 0.054399\n",
      "iter 300:\t Loss = 0.042802\n",
      "-----------------------------------------------\n",
      "Training epoch :  237\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071500\n",
      "iter  50:\t Loss = 0.072718\n",
      "iter 100:\t Loss = 0.038630\n",
      "iter 150:\t Loss = 0.061895\n",
      "iter 200:\t Loss = 0.062228\n",
      "iter 250:\t Loss = 0.054372\n",
      "iter 300:\t Loss = 0.042770\n",
      "-----------------------------------------------\n",
      "Training epoch :  238\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071429\n",
      "iter  50:\t Loss = 0.072693\n",
      "iter 100:\t Loss = 0.038591\n",
      "iter 150:\t Loss = 0.061892\n",
      "iter 200:\t Loss = 0.062184\n",
      "iter 250:\t Loss = 0.054346\n",
      "iter 300:\t Loss = 0.042738\n",
      "-----------------------------------------------\n",
      "Training epoch :  239\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071358\n",
      "iter  50:\t Loss = 0.072666\n",
      "iter 100:\t Loss = 0.038553\n",
      "iter 150:\t Loss = 0.061888\n",
      "iter 200:\t Loss = 0.062139\n",
      "iter 250:\t Loss = 0.054320\n",
      "iter 300:\t Loss = 0.042706\n",
      "-----------------------------------------------\n",
      "Training epoch :  240\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071286\n",
      "iter  50:\t Loss = 0.072640\n",
      "iter 100:\t Loss = 0.038514\n",
      "iter 150:\t Loss = 0.061884\n",
      "iter 200:\t Loss = 0.062095\n",
      "iter 250:\t Loss = 0.054295\n",
      "iter 300:\t Loss = 0.042675\n",
      "-----------------------------------------------\n",
      "Training epoch :  241\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071214\n",
      "iter  50:\t Loss = 0.072613\n",
      "iter 100:\t Loss = 0.038475\n",
      "iter 150:\t Loss = 0.061880\n",
      "iter 200:\t Loss = 0.062051\n",
      "iter 250:\t Loss = 0.054269\n",
      "iter 300:\t Loss = 0.042644\n",
      "-----------------------------------------------\n",
      "Training epoch :  242\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.072586\n",
      "iter 100:\t Loss = 0.038436\n",
      "iter 150:\t Loss = 0.061876\n",
      "iter 200:\t Loss = 0.062007\n",
      "iter 250:\t Loss = 0.054243\n",
      "iter 300:\t Loss = 0.042613\n",
      "-----------------------------------------------\n",
      "Training epoch :  243\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.071069\n",
      "iter  50:\t Loss = 0.072559\n",
      "iter 100:\t Loss = 0.038397\n",
      "iter 150:\t Loss = 0.061872\n",
      "iter 200:\t Loss = 0.061964\n",
      "iter 250:\t Loss = 0.054218\n",
      "iter 300:\t Loss = 0.042583\n",
      "-----------------------------------------------\n",
      "Training epoch :  244\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070996\n",
      "iter  50:\t Loss = 0.072531\n",
      "iter 100:\t Loss = 0.038358\n",
      "iter 150:\t Loss = 0.061868\n",
      "iter 200:\t Loss = 0.061920\n",
      "iter 250:\t Loss = 0.054193\n",
      "iter 300:\t Loss = 0.042552\n",
      "-----------------------------------------------\n",
      "Training epoch :  245\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070923\n",
      "iter  50:\t Loss = 0.072503\n",
      "iter 100:\t Loss = 0.038318\n",
      "iter 150:\t Loss = 0.061864\n",
      "iter 200:\t Loss = 0.061877\n",
      "iter 250:\t Loss = 0.054168\n",
      "iter 300:\t Loss = 0.042522\n",
      "-----------------------------------------------\n",
      "Training epoch :  246\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070849\n",
      "iter  50:\t Loss = 0.072474\n",
      "iter 100:\t Loss = 0.038279\n",
      "iter 150:\t Loss = 0.061860\n",
      "iter 200:\t Loss = 0.061834\n",
      "iter 250:\t Loss = 0.054143\n",
      "iter 300:\t Loss = 0.042493\n",
      "-----------------------------------------------\n",
      "Training epoch :  247\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070775\n",
      "iter  50:\t Loss = 0.072445\n",
      "iter 100:\t Loss = 0.038239\n",
      "iter 150:\t Loss = 0.061855\n",
      "iter 200:\t Loss = 0.061792\n",
      "iter 250:\t Loss = 0.054118\n",
      "iter 300:\t Loss = 0.042463\n",
      "-----------------------------------------------\n",
      "Training epoch :  248\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070700\n",
      "iter  50:\t Loss = 0.072416\n",
      "iter 100:\t Loss = 0.038200\n",
      "iter 150:\t Loss = 0.061851\n",
      "iter 200:\t Loss = 0.061750\n",
      "iter 250:\t Loss = 0.054093\n",
      "iter 300:\t Loss = 0.042434\n",
      "-----------------------------------------------\n",
      "Training epoch :  249\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070625\n",
      "iter  50:\t Loss = 0.072387\n",
      "iter 100:\t Loss = 0.038160\n",
      "iter 150:\t Loss = 0.061846\n",
      "iter 200:\t Loss = 0.061707\n",
      "iter 250:\t Loss = 0.054068\n",
      "iter 300:\t Loss = 0.042405\n",
      "-----------------------------------------------\n",
      "Training epoch :  250\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070550\n",
      "iter  50:\t Loss = 0.072358\n",
      "iter 100:\t Loss = 0.038120\n",
      "iter 150:\t Loss = 0.061842\n",
      "iter 200:\t Loss = 0.061666\n",
      "iter 250:\t Loss = 0.054044\n",
      "iter 300:\t Loss = 0.042377\n",
      "-----------------------------------------------\n",
      "Training epoch :  251\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070474\n",
      "iter  50:\t Loss = 0.072328\n",
      "iter 100:\t Loss = 0.038080\n",
      "iter 150:\t Loss = 0.061837\n",
      "iter 200:\t Loss = 0.061624\n",
      "iter 250:\t Loss = 0.054019\n",
      "iter 300:\t Loss = 0.042348\n",
      "-----------------------------------------------\n",
      "Training epoch :  252\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070397\n",
      "iter  50:\t Loss = 0.072298\n",
      "iter 100:\t Loss = 0.038040\n",
      "iter 150:\t Loss = 0.061832\n",
      "iter 200:\t Loss = 0.061582\n",
      "iter 250:\t Loss = 0.053995\n",
      "iter 300:\t Loss = 0.042320\n",
      "-----------------------------------------------\n",
      "Training epoch :  253\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070321\n",
      "iter  50:\t Loss = 0.072268\n",
      "iter 100:\t Loss = 0.038000\n",
      "iter 150:\t Loss = 0.061827\n",
      "iter 200:\t Loss = 0.061541\n",
      "iter 250:\t Loss = 0.053970\n",
      "iter 300:\t Loss = 0.042293\n",
      "-----------------------------------------------\n",
      "Training epoch :  254\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070244\n",
      "iter  50:\t Loss = 0.072238\n",
      "iter 100:\t Loss = 0.037960\n",
      "iter 150:\t Loss = 0.061822\n",
      "iter 200:\t Loss = 0.061500\n",
      "iter 250:\t Loss = 0.053946\n",
      "iter 300:\t Loss = 0.042265\n",
      "-----------------------------------------------\n",
      "Training epoch :  255\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070167\n",
      "iter  50:\t Loss = 0.072207\n",
      "iter 100:\t Loss = 0.037920\n",
      "iter 150:\t Loss = 0.061817\n",
      "iter 200:\t Loss = 0.061460\n",
      "iter 250:\t Loss = 0.053922\n",
      "iter 300:\t Loss = 0.042238\n",
      "-----------------------------------------------\n",
      "Training epoch :  256\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070089\n",
      "iter  50:\t Loss = 0.072176\n",
      "iter 100:\t Loss = 0.037880\n",
      "iter 150:\t Loss = 0.061811\n",
      "iter 200:\t Loss = 0.061419\n",
      "iter 250:\t Loss = 0.053898\n",
      "iter 300:\t Loss = 0.042211\n",
      "-----------------------------------------------\n",
      "Training epoch :  257\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.070011\n",
      "iter  50:\t Loss = 0.072145\n",
      "iter 100:\t Loss = 0.037840\n",
      "iter 150:\t Loss = 0.061806\n",
      "iter 200:\t Loss = 0.061379\n",
      "iter 250:\t Loss = 0.053874\n",
      "iter 300:\t Loss = 0.042184\n",
      "-----------------------------------------------\n",
      "Training epoch :  258\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069933\n",
      "iter  50:\t Loss = 0.072115\n",
      "iter 100:\t Loss = 0.037800\n",
      "iter 150:\t Loss = 0.061800\n",
      "iter 200:\t Loss = 0.061339\n",
      "iter 250:\t Loss = 0.053850\n",
      "iter 300:\t Loss = 0.042158\n",
      "-----------------------------------------------\n",
      "Training epoch :  259\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069854\n",
      "iter  50:\t Loss = 0.072084\n",
      "iter 100:\t Loss = 0.037759\n",
      "iter 150:\t Loss = 0.061795\n",
      "iter 200:\t Loss = 0.061300\n",
      "iter 250:\t Loss = 0.053827\n",
      "iter 300:\t Loss = 0.042132\n",
      "-----------------------------------------------\n",
      "Training epoch :  260\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069775\n",
      "iter  50:\t Loss = 0.072052\n",
      "iter 100:\t Loss = 0.037719\n",
      "iter 150:\t Loss = 0.061789\n",
      "iter 200:\t Loss = 0.061260\n",
      "iter 250:\t Loss = 0.053803\n",
      "iter 300:\t Loss = 0.042106\n",
      "-----------------------------------------------\n",
      "Training epoch :  261\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069696\n",
      "iter  50:\t Loss = 0.072021\n",
      "iter 100:\t Loss = 0.037679\n",
      "iter 150:\t Loss = 0.061783\n",
      "iter 200:\t Loss = 0.061221\n",
      "iter 250:\t Loss = 0.053779\n",
      "iter 300:\t Loss = 0.042081\n",
      "-----------------------------------------------\n",
      "Training epoch :  262\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069617\n",
      "iter  50:\t Loss = 0.071990\n",
      "iter 100:\t Loss = 0.037639\n",
      "iter 150:\t Loss = 0.061777\n",
      "iter 200:\t Loss = 0.061182\n",
      "iter 250:\t Loss = 0.053756\n",
      "iter 300:\t Loss = 0.042055\n",
      "-----------------------------------------------\n",
      "Training epoch :  263\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069537\n",
      "iter  50:\t Loss = 0.071959\n",
      "iter 100:\t Loss = 0.037599\n",
      "iter 150:\t Loss = 0.061771\n",
      "iter 200:\t Loss = 0.061144\n",
      "iter 250:\t Loss = 0.053733\n",
      "iter 300:\t Loss = 0.042030\n",
      "-----------------------------------------------\n",
      "Training epoch :  264\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069457\n",
      "iter  50:\t Loss = 0.071927\n",
      "iter 100:\t Loss = 0.037559\n",
      "iter 150:\t Loss = 0.061765\n",
      "iter 200:\t Loss = 0.061106\n",
      "iter 250:\t Loss = 0.053709\n",
      "iter 300:\t Loss = 0.042006\n",
      "-----------------------------------------------\n",
      "Training epoch :  265\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069377\n",
      "iter  50:\t Loss = 0.071896\n",
      "iter 100:\t Loss = 0.037519\n",
      "iter 150:\t Loss = 0.061759\n",
      "iter 200:\t Loss = 0.061068\n",
      "iter 250:\t Loss = 0.053686\n",
      "iter 300:\t Loss = 0.041982\n",
      "-----------------------------------------------\n",
      "Training epoch :  266\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069297\n",
      "iter  50:\t Loss = 0.071865\n",
      "iter 100:\t Loss = 0.037479\n",
      "iter 150:\t Loss = 0.061753\n",
      "iter 200:\t Loss = 0.061031\n",
      "iter 250:\t Loss = 0.053663\n",
      "iter 300:\t Loss = 0.041958\n",
      "-----------------------------------------------\n",
      "Training epoch :  267\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069217\n",
      "iter  50:\t Loss = 0.071834\n",
      "iter 100:\t Loss = 0.037440\n",
      "iter 150:\t Loss = 0.061747\n",
      "iter 200:\t Loss = 0.060993\n",
      "iter 250:\t Loss = 0.053640\n",
      "iter 300:\t Loss = 0.041934\n",
      "-----------------------------------------------\n",
      "Training epoch :  268\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069137\n",
      "iter  50:\t Loss = 0.071803\n",
      "iter 100:\t Loss = 0.037400\n",
      "iter 150:\t Loss = 0.061741\n",
      "iter 200:\t Loss = 0.060957\n",
      "iter 250:\t Loss = 0.053617\n",
      "iter 300:\t Loss = 0.041910\n",
      "-----------------------------------------------\n",
      "Training epoch :  269\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.069057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.071772\n",
      "iter 100:\t Loss = 0.037360\n",
      "iter 150:\t Loss = 0.061735\n",
      "iter 200:\t Loss = 0.060920\n",
      "iter 250:\t Loss = 0.053594\n",
      "iter 300:\t Loss = 0.041887\n",
      "-----------------------------------------------\n",
      "Training epoch :  270\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068977\n",
      "iter  50:\t Loss = 0.071741\n",
      "iter 100:\t Loss = 0.037321\n",
      "iter 150:\t Loss = 0.061728\n",
      "iter 200:\t Loss = 0.060884\n",
      "iter 250:\t Loss = 0.053571\n",
      "iter 300:\t Loss = 0.041864\n",
      "-----------------------------------------------\n",
      "Training epoch :  271\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068897\n",
      "iter  50:\t Loss = 0.071710\n",
      "iter 100:\t Loss = 0.037282\n",
      "iter 150:\t Loss = 0.061722\n",
      "iter 200:\t Loss = 0.060848\n",
      "iter 250:\t Loss = 0.053549\n",
      "iter 300:\t Loss = 0.041842\n",
      "-----------------------------------------------\n",
      "Training epoch :  272\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068817\n",
      "iter  50:\t Loss = 0.071679\n",
      "iter 100:\t Loss = 0.037243\n",
      "iter 150:\t Loss = 0.061716\n",
      "iter 200:\t Loss = 0.060813\n",
      "iter 250:\t Loss = 0.053526\n",
      "iter 300:\t Loss = 0.041820\n",
      "-----------------------------------------------\n",
      "Training epoch :  273\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068738\n",
      "iter  50:\t Loss = 0.071649\n",
      "iter 100:\t Loss = 0.037204\n",
      "iter 150:\t Loss = 0.061709\n",
      "iter 200:\t Loss = 0.060778\n",
      "iter 250:\t Loss = 0.053504\n",
      "iter 300:\t Loss = 0.041798\n",
      "-----------------------------------------------\n",
      "Training epoch :  274\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068658\n",
      "iter  50:\t Loss = 0.071618\n",
      "iter 100:\t Loss = 0.037165\n",
      "iter 150:\t Loss = 0.061703\n",
      "iter 200:\t Loss = 0.060743\n",
      "iter 250:\t Loss = 0.053481\n",
      "iter 300:\t Loss = 0.041776\n",
      "-----------------------------------------------\n",
      "Training epoch :  275\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068579\n",
      "iter  50:\t Loss = 0.071588\n",
      "iter 100:\t Loss = 0.037127\n",
      "iter 150:\t Loss = 0.061697\n",
      "iter 200:\t Loss = 0.060709\n",
      "iter 250:\t Loss = 0.053459\n",
      "iter 300:\t Loss = 0.041755\n",
      "-----------------------------------------------\n",
      "Training epoch :  276\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068500\n",
      "iter  50:\t Loss = 0.071558\n",
      "iter 100:\t Loss = 0.037089\n",
      "iter 150:\t Loss = 0.061691\n",
      "iter 200:\t Loss = 0.060676\n",
      "iter 250:\t Loss = 0.053437\n",
      "iter 300:\t Loss = 0.041734\n",
      "-----------------------------------------------\n",
      "Training epoch :  277\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068421\n",
      "iter  50:\t Loss = 0.071528\n",
      "iter 100:\t Loss = 0.037051\n",
      "iter 150:\t Loss = 0.061685\n",
      "iter 200:\t Loss = 0.060642\n",
      "iter 250:\t Loss = 0.053415\n",
      "iter 300:\t Loss = 0.041714\n",
      "-----------------------------------------------\n",
      "Training epoch :  278\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068343\n",
      "iter  50:\t Loss = 0.071499\n",
      "iter 100:\t Loss = 0.037013\n",
      "iter 150:\t Loss = 0.061679\n",
      "iter 200:\t Loss = 0.060609\n",
      "iter 250:\t Loss = 0.053392\n",
      "iter 300:\t Loss = 0.041693\n",
      "-----------------------------------------------\n",
      "Training epoch :  279\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068265\n",
      "iter  50:\t Loss = 0.071469\n",
      "iter 100:\t Loss = 0.036975\n",
      "iter 150:\t Loss = 0.061672\n",
      "iter 200:\t Loss = 0.060577\n",
      "iter 250:\t Loss = 0.053371\n",
      "iter 300:\t Loss = 0.041673\n",
      "-----------------------------------------------\n",
      "Training epoch :  280\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068187\n",
      "iter  50:\t Loss = 0.071440\n",
      "iter 100:\t Loss = 0.036938\n",
      "iter 150:\t Loss = 0.061666\n",
      "iter 200:\t Loss = 0.060545\n",
      "iter 250:\t Loss = 0.053349\n",
      "iter 300:\t Loss = 0.041654\n",
      "-----------------------------------------------\n",
      "Training epoch :  281\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068110\n",
      "iter  50:\t Loss = 0.071411\n",
      "iter 100:\t Loss = 0.036901\n",
      "iter 150:\t Loss = 0.061661\n",
      "iter 200:\t Loss = 0.060513\n",
      "iter 250:\t Loss = 0.053327\n",
      "iter 300:\t Loss = 0.041634\n",
      "-----------------------------------------------\n",
      "Training epoch :  282\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.068033\n",
      "iter  50:\t Loss = 0.071383\n",
      "iter 100:\t Loss = 0.036864\n",
      "iter 150:\t Loss = 0.061655\n",
      "iter 200:\t Loss = 0.060482\n",
      "iter 250:\t Loss = 0.053306\n",
      "iter 300:\t Loss = 0.041615\n",
      "-----------------------------------------------\n",
      "Training epoch :  283\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067957\n",
      "iter  50:\t Loss = 0.071354\n",
      "iter 100:\t Loss = 0.036828\n",
      "iter 150:\t Loss = 0.061649\n",
      "iter 200:\t Loss = 0.060451\n",
      "iter 250:\t Loss = 0.053284\n",
      "iter 300:\t Loss = 0.041596\n",
      "-----------------------------------------------\n",
      "Training epoch :  284\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067882\n",
      "iter  50:\t Loss = 0.071327\n",
      "iter 100:\t Loss = 0.036792\n",
      "iter 150:\t Loss = 0.061643\n",
      "iter 200:\t Loss = 0.060420\n",
      "iter 250:\t Loss = 0.053263\n",
      "iter 300:\t Loss = 0.041578\n",
      "-----------------------------------------------\n",
      "Training epoch :  285\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067807\n",
      "iter  50:\t Loss = 0.071299\n",
      "iter 100:\t Loss = 0.036756\n",
      "iter 150:\t Loss = 0.061638\n",
      "iter 200:\t Loss = 0.060390\n",
      "iter 250:\t Loss = 0.053241\n",
      "iter 300:\t Loss = 0.041560\n",
      "-----------------------------------------------\n",
      "Training epoch :  286\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067732\n",
      "iter  50:\t Loss = 0.071271\n",
      "iter 100:\t Loss = 0.036720\n",
      "iter 150:\t Loss = 0.061632\n",
      "iter 200:\t Loss = 0.060361\n",
      "iter 250:\t Loss = 0.053220\n",
      "iter 300:\t Loss = 0.041542\n",
      "-----------------------------------------------\n",
      "Training epoch :  287\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067659\n",
      "iter  50:\t Loss = 0.071244\n",
      "iter 100:\t Loss = 0.036685\n",
      "iter 150:\t Loss = 0.061627\n",
      "iter 200:\t Loss = 0.060332\n",
      "iter 250:\t Loss = 0.053199\n",
      "iter 300:\t Loss = 0.041524\n",
      "-----------------------------------------------\n",
      "Training epoch :  288\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067586\n",
      "iter  50:\t Loss = 0.071217\n",
      "iter 100:\t Loss = 0.036650\n",
      "iter 150:\t Loss = 0.061622\n",
      "iter 200:\t Loss = 0.060303\n",
      "iter 250:\t Loss = 0.053178\n",
      "iter 300:\t Loss = 0.041506\n",
      "-----------------------------------------------\n",
      "Training epoch :  289\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067514\n",
      "iter  50:\t Loss = 0.071191\n",
      "iter 100:\t Loss = 0.036615\n",
      "iter 150:\t Loss = 0.061617\n",
      "iter 200:\t Loss = 0.060275\n",
      "iter 250:\t Loss = 0.053158\n",
      "iter 300:\t Loss = 0.041489\n",
      "-----------------------------------------------\n",
      "Training epoch :  290\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067443\n",
      "iter  50:\t Loss = 0.071165\n",
      "iter 100:\t Loss = 0.036581\n",
      "iter 150:\t Loss = 0.061612\n",
      "iter 200:\t Loss = 0.060247\n",
      "iter 250:\t Loss = 0.053137\n",
      "iter 300:\t Loss = 0.041472\n",
      "-----------------------------------------------\n",
      "Training epoch :  291\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067372\n",
      "iter  50:\t Loss = 0.071139\n",
      "iter 100:\t Loss = 0.036547\n",
      "iter 150:\t Loss = 0.061607\n",
      "iter 200:\t Loss = 0.060219\n",
      "iter 250:\t Loss = 0.053117\n",
      "iter 300:\t Loss = 0.041455\n",
      "-----------------------------------------------\n",
      "Training epoch :  292\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067303\n",
      "iter  50:\t Loss = 0.071113\n",
      "iter 100:\t Loss = 0.036513\n",
      "iter 150:\t Loss = 0.061602\n",
      "iter 200:\t Loss = 0.060192\n",
      "iter 250:\t Loss = 0.053096\n",
      "iter 300:\t Loss = 0.041439\n",
      "-----------------------------------------------\n",
      "Training epoch :  293\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067234\n",
      "iter  50:\t Loss = 0.071088\n",
      "iter 100:\t Loss = 0.036480\n",
      "iter 150:\t Loss = 0.061598\n",
      "iter 200:\t Loss = 0.060165\n",
      "iter 250:\t Loss = 0.053076\n",
      "iter 300:\t Loss = 0.041423\n",
      "-----------------------------------------------\n",
      "Training epoch :  294\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067166\n",
      "iter  50:\t Loss = 0.071063\n",
      "iter 100:\t Loss = 0.036447\n",
      "iter 150:\t Loss = 0.061593\n",
      "iter 200:\t Loss = 0.060139\n",
      "iter 250:\t Loss = 0.053056\n",
      "iter 300:\t Loss = 0.041407\n",
      "-----------------------------------------------\n",
      "Training epoch :  295\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067099\n",
      "iter  50:\t Loss = 0.071039\n",
      "iter 100:\t Loss = 0.036414\n",
      "iter 150:\t Loss = 0.061589\n",
      "iter 200:\t Loss = 0.060113\n",
      "iter 250:\t Loss = 0.053036\n",
      "iter 300:\t Loss = 0.041391\n",
      "-----------------------------------------------\n",
      "Training epoch :  296\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.067032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.071015\n",
      "iter 100:\t Loss = 0.036381\n",
      "iter 150:\t Loss = 0.061585\n",
      "iter 200:\t Loss = 0.060087\n",
      "iter 250:\t Loss = 0.053016\n",
      "iter 300:\t Loss = 0.041375\n",
      "-----------------------------------------------\n",
      "Training epoch :  297\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066967\n",
      "iter  50:\t Loss = 0.070991\n",
      "iter 100:\t Loss = 0.036349\n",
      "iter 150:\t Loss = 0.061581\n",
      "iter 200:\t Loss = 0.060062\n",
      "iter 250:\t Loss = 0.052996\n",
      "iter 300:\t Loss = 0.041360\n",
      "-----------------------------------------------\n",
      "Training epoch :  298\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066903\n",
      "iter  50:\t Loss = 0.070967\n",
      "iter 100:\t Loss = 0.036317\n",
      "iter 150:\t Loss = 0.061577\n",
      "iter 200:\t Loss = 0.060037\n",
      "iter 250:\t Loss = 0.052977\n",
      "iter 300:\t Loss = 0.041345\n",
      "-----------------------------------------------\n",
      "Training epoch :  299\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066840\n",
      "iter  50:\t Loss = 0.070944\n",
      "iter 100:\t Loss = 0.036286\n",
      "iter 150:\t Loss = 0.061573\n",
      "iter 200:\t Loss = 0.060013\n",
      "iter 250:\t Loss = 0.052958\n",
      "iter 300:\t Loss = 0.041330\n",
      "-----------------------------------------------\n",
      "Training epoch :  300\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066777\n",
      "iter  50:\t Loss = 0.070921\n",
      "iter 100:\t Loss = 0.036255\n",
      "iter 150:\t Loss = 0.061570\n",
      "iter 200:\t Loss = 0.059989\n",
      "iter 250:\t Loss = 0.052939\n",
      "iter 300:\t Loss = 0.041315\n",
      "-----------------------------------------------\n",
      "Training epoch :  301\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066716\n",
      "iter  50:\t Loss = 0.070899\n",
      "iter 100:\t Loss = 0.036223\n",
      "iter 150:\t Loss = 0.061566\n",
      "iter 200:\t Loss = 0.059965\n",
      "iter 250:\t Loss = 0.052920\n",
      "iter 300:\t Loss = 0.041300\n",
      "-----------------------------------------------\n",
      "Training epoch :  302\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066655\n",
      "iter  50:\t Loss = 0.070877\n",
      "iter 100:\t Loss = 0.036193\n",
      "iter 150:\t Loss = 0.061563\n",
      "iter 200:\t Loss = 0.059941\n",
      "iter 250:\t Loss = 0.052901\n",
      "iter 300:\t Loss = 0.041285\n",
      "-----------------------------------------------\n",
      "Training epoch :  303\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066596\n",
      "iter  50:\t Loss = 0.070855\n",
      "iter 100:\t Loss = 0.036163\n",
      "iter 150:\t Loss = 0.061560\n",
      "iter 200:\t Loss = 0.059918\n",
      "iter 250:\t Loss = 0.052882\n",
      "iter 300:\t Loss = 0.041271\n",
      "-----------------------------------------------\n",
      "Training epoch :  304\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066538\n",
      "iter  50:\t Loss = 0.070833\n",
      "iter 100:\t Loss = 0.036133\n",
      "iter 150:\t Loss = 0.061557\n",
      "iter 200:\t Loss = 0.059894\n",
      "iter 250:\t Loss = 0.052864\n",
      "iter 300:\t Loss = 0.041257\n",
      "-----------------------------------------------\n",
      "Training epoch :  305\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066480\n",
      "iter  50:\t Loss = 0.070812\n",
      "iter 100:\t Loss = 0.036103\n",
      "iter 150:\t Loss = 0.061554\n",
      "iter 200:\t Loss = 0.059872\n",
      "iter 250:\t Loss = 0.052845\n",
      "iter 300:\t Loss = 0.041243\n",
      "-----------------------------------------------\n",
      "Training epoch :  306\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066424\n",
      "iter  50:\t Loss = 0.070792\n",
      "iter 100:\t Loss = 0.036073\n",
      "iter 150:\t Loss = 0.061552\n",
      "iter 200:\t Loss = 0.059849\n",
      "iter 250:\t Loss = 0.052827\n",
      "iter 300:\t Loss = 0.041229\n",
      "-----------------------------------------------\n",
      "Training epoch :  307\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066368\n",
      "iter  50:\t Loss = 0.070771\n",
      "iter 100:\t Loss = 0.036044\n",
      "iter 150:\t Loss = 0.061549\n",
      "iter 200:\t Loss = 0.059827\n",
      "iter 250:\t Loss = 0.052809\n",
      "iter 300:\t Loss = 0.041215\n",
      "-----------------------------------------------\n",
      "Training epoch :  308\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066314\n",
      "iter  50:\t Loss = 0.070751\n",
      "iter 100:\t Loss = 0.036015\n",
      "iter 150:\t Loss = 0.061547\n",
      "iter 200:\t Loss = 0.059805\n",
      "iter 250:\t Loss = 0.052791\n",
      "iter 300:\t Loss = 0.041201\n",
      "-----------------------------------------------\n",
      "Training epoch :  309\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066261\n",
      "iter  50:\t Loss = 0.070731\n",
      "iter 100:\t Loss = 0.035987\n",
      "iter 150:\t Loss = 0.061545\n",
      "iter 200:\t Loss = 0.059783\n",
      "iter 250:\t Loss = 0.052773\n",
      "iter 300:\t Loss = 0.041187\n",
      "-----------------------------------------------\n",
      "Training epoch :  310\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066208\n",
      "iter  50:\t Loss = 0.070712\n",
      "iter 100:\t Loss = 0.035958\n",
      "iter 150:\t Loss = 0.061542\n",
      "iter 200:\t Loss = 0.059761\n",
      "iter 250:\t Loss = 0.052755\n",
      "iter 300:\t Loss = 0.041173\n",
      "-----------------------------------------------\n",
      "Training epoch :  311\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066157\n",
      "iter  50:\t Loss = 0.070693\n",
      "iter 100:\t Loss = 0.035930\n",
      "iter 150:\t Loss = 0.061541\n",
      "iter 200:\t Loss = 0.059740\n",
      "iter 250:\t Loss = 0.052738\n",
      "iter 300:\t Loss = 0.041160\n",
      "-----------------------------------------------\n",
      "Training epoch :  312\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066106\n",
      "iter  50:\t Loss = 0.070674\n",
      "iter 100:\t Loss = 0.035902\n",
      "iter 150:\t Loss = 0.061539\n",
      "iter 200:\t Loss = 0.059719\n",
      "iter 250:\t Loss = 0.052720\n",
      "iter 300:\t Loss = 0.041146\n",
      "-----------------------------------------------\n",
      "Training epoch :  313\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066057\n",
      "iter  50:\t Loss = 0.070656\n",
      "iter 100:\t Loss = 0.035875\n",
      "iter 150:\t Loss = 0.061537\n",
      "iter 200:\t Loss = 0.059698\n",
      "iter 250:\t Loss = 0.052703\n",
      "iter 300:\t Loss = 0.041132\n",
      "-----------------------------------------------\n",
      "Training epoch :  314\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.066008\n",
      "iter  50:\t Loss = 0.070637\n",
      "iter 100:\t Loss = 0.035847\n",
      "iter 150:\t Loss = 0.061535\n",
      "iter 200:\t Loss = 0.059677\n",
      "iter 250:\t Loss = 0.052686\n",
      "iter 300:\t Loss = 0.041119\n",
      "-----------------------------------------------\n",
      "Training epoch :  315\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065961\n",
      "iter  50:\t Loss = 0.070620\n",
      "iter 100:\t Loss = 0.035820\n",
      "iter 150:\t Loss = 0.061534\n",
      "iter 200:\t Loss = 0.059656\n",
      "iter 250:\t Loss = 0.052669\n",
      "iter 300:\t Loss = 0.041105\n",
      "-----------------------------------------------\n",
      "Training epoch :  316\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065914\n",
      "iter  50:\t Loss = 0.070602\n",
      "iter 100:\t Loss = 0.035793\n",
      "iter 150:\t Loss = 0.061533\n",
      "iter 200:\t Loss = 0.059636\n",
      "iter 250:\t Loss = 0.052652\n",
      "iter 300:\t Loss = 0.041092\n",
      "-----------------------------------------------\n",
      "Training epoch :  317\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065868\n",
      "iter  50:\t Loss = 0.070585\n",
      "iter 100:\t Loss = 0.035767\n",
      "iter 150:\t Loss = 0.061531\n",
      "iter 200:\t Loss = 0.059615\n",
      "iter 250:\t Loss = 0.052635\n",
      "iter 300:\t Loss = 0.041079\n",
      "-----------------------------------------------\n",
      "Training epoch :  318\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065823\n",
      "iter  50:\t Loss = 0.070568\n",
      "iter 100:\t Loss = 0.035740\n",
      "iter 150:\t Loss = 0.061530\n",
      "iter 200:\t Loss = 0.059595\n",
      "iter 250:\t Loss = 0.052619\n",
      "iter 300:\t Loss = 0.041065\n",
      "-----------------------------------------------\n",
      "Training epoch :  319\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065780\n",
      "iter  50:\t Loss = 0.070551\n",
      "iter 100:\t Loss = 0.035714\n",
      "iter 150:\t Loss = 0.061529\n",
      "iter 200:\t Loss = 0.059574\n",
      "iter 250:\t Loss = 0.052602\n",
      "iter 300:\t Loss = 0.041052\n",
      "-----------------------------------------------\n",
      "Training epoch :  320\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065736\n",
      "iter  50:\t Loss = 0.070535\n",
      "iter 100:\t Loss = 0.035688\n",
      "iter 150:\t Loss = 0.061528\n",
      "iter 200:\t Loss = 0.059554\n",
      "iter 250:\t Loss = 0.052586\n",
      "iter 300:\t Loss = 0.041038\n",
      "-----------------------------------------------\n",
      "Training epoch :  321\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065694\n",
      "iter  50:\t Loss = 0.070519\n",
      "iter 100:\t Loss = 0.035662\n",
      "iter 150:\t Loss = 0.061527\n",
      "iter 200:\t Loss = 0.059534\n",
      "iter 250:\t Loss = 0.052570\n",
      "iter 300:\t Loss = 0.041025\n",
      "-----------------------------------------------\n",
      "Training epoch :  322\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065653\n",
      "iter  50:\t Loss = 0.070503\n",
      "iter 100:\t Loss = 0.035637\n",
      "iter 150:\t Loss = 0.061526\n",
      "iter 200:\t Loss = 0.059514\n",
      "iter 250:\t Loss = 0.052553\n",
      "iter 300:\t Loss = 0.041012\n",
      "-----------------------------------------------\n",
      "Training epoch :  323\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  50:\t Loss = 0.070488\n",
      "iter 100:\t Loss = 0.035611\n",
      "iter 150:\t Loss = 0.061526\n",
      "iter 200:\t Loss = 0.059494\n",
      "iter 250:\t Loss = 0.052537\n",
      "iter 300:\t Loss = 0.040999\n",
      "-----------------------------------------------\n",
      "Training epoch :  324\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065572\n",
      "iter  50:\t Loss = 0.070472\n",
      "iter 100:\t Loss = 0.035586\n",
      "iter 150:\t Loss = 0.061525\n",
      "iter 200:\t Loss = 0.059474\n",
      "iter 250:\t Loss = 0.052521\n",
      "iter 300:\t Loss = 0.040985\n",
      "-----------------------------------------------\n",
      "Training epoch :  325\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065533\n",
      "iter  50:\t Loss = 0.070457\n",
      "iter 100:\t Loss = 0.035562\n",
      "iter 150:\t Loss = 0.061524\n",
      "iter 200:\t Loss = 0.059454\n",
      "iter 250:\t Loss = 0.052505\n",
      "iter 300:\t Loss = 0.040972\n",
      "-----------------------------------------------\n",
      "Training epoch :  326\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065494\n",
      "iter  50:\t Loss = 0.070443\n",
      "iter 100:\t Loss = 0.035537\n",
      "iter 150:\t Loss = 0.061524\n",
      "iter 200:\t Loss = 0.059434\n",
      "iter 250:\t Loss = 0.052489\n",
      "iter 300:\t Loss = 0.040959\n",
      "-----------------------------------------------\n",
      "Training epoch :  327\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065456\n",
      "iter  50:\t Loss = 0.070428\n",
      "iter 100:\t Loss = 0.035513\n",
      "iter 150:\t Loss = 0.061524\n",
      "iter 200:\t Loss = 0.059415\n",
      "iter 250:\t Loss = 0.052473\n",
      "iter 300:\t Loss = 0.040946\n",
      "-----------------------------------------------\n",
      "Training epoch :  328\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065418\n",
      "iter  50:\t Loss = 0.070414\n",
      "iter 100:\t Loss = 0.035488\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059395\n",
      "iter 250:\t Loss = 0.052457\n",
      "iter 300:\t Loss = 0.040933\n",
      "-----------------------------------------------\n",
      "Training epoch :  329\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065382\n",
      "iter  50:\t Loss = 0.070400\n",
      "iter 100:\t Loss = 0.035465\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059375\n",
      "iter 250:\t Loss = 0.052442\n",
      "iter 300:\t Loss = 0.040920\n",
      "-----------------------------------------------\n",
      "Training epoch :  330\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065345\n",
      "iter  50:\t Loss = 0.070386\n",
      "iter 100:\t Loss = 0.035441\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059356\n",
      "iter 250:\t Loss = 0.052426\n",
      "iter 300:\t Loss = 0.040907\n",
      "-----------------------------------------------\n",
      "Training epoch :  331\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065309\n",
      "iter  50:\t Loss = 0.070373\n",
      "iter 100:\t Loss = 0.035417\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059336\n",
      "iter 250:\t Loss = 0.052411\n",
      "iter 300:\t Loss = 0.040895\n",
      "-----------------------------------------------\n",
      "Training epoch :  332\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065274\n",
      "iter  50:\t Loss = 0.070360\n",
      "iter 100:\t Loss = 0.035394\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059316\n",
      "iter 250:\t Loss = 0.052395\n",
      "iter 300:\t Loss = 0.040882\n",
      "-----------------------------------------------\n",
      "Training epoch :  333\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065239\n",
      "iter  50:\t Loss = 0.070347\n",
      "iter 100:\t Loss = 0.035372\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059297\n",
      "iter 250:\t Loss = 0.052380\n",
      "iter 300:\t Loss = 0.040870\n",
      "-----------------------------------------------\n",
      "Training epoch :  334\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065204\n",
      "iter  50:\t Loss = 0.070334\n",
      "iter 100:\t Loss = 0.035349\n",
      "iter 150:\t Loss = 0.061522\n",
      "iter 200:\t Loss = 0.059278\n",
      "iter 250:\t Loss = 0.052364\n",
      "iter 300:\t Loss = 0.040857\n",
      "-----------------------------------------------\n",
      "Training epoch :  335\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065170\n",
      "iter  50:\t Loss = 0.070321\n",
      "iter 100:\t Loss = 0.035327\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059258\n",
      "iter 250:\t Loss = 0.052349\n",
      "iter 300:\t Loss = 0.040845\n",
      "-----------------------------------------------\n",
      "Training epoch :  336\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065136\n",
      "iter  50:\t Loss = 0.070309\n",
      "iter 100:\t Loss = 0.035305\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059239\n",
      "iter 250:\t Loss = 0.052334\n",
      "iter 300:\t Loss = 0.040833\n",
      "-----------------------------------------------\n",
      "Training epoch :  337\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065102\n",
      "iter  50:\t Loss = 0.070297\n",
      "iter 100:\t Loss = 0.035283\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059220\n",
      "iter 250:\t Loss = 0.052319\n",
      "iter 300:\t Loss = 0.040822\n",
      "-----------------------------------------------\n",
      "Training epoch :  338\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065069\n",
      "iter  50:\t Loss = 0.070285\n",
      "iter 100:\t Loss = 0.035261\n",
      "iter 150:\t Loss = 0.061523\n",
      "iter 200:\t Loss = 0.059201\n",
      "iter 250:\t Loss = 0.052304\n",
      "iter 300:\t Loss = 0.040810\n",
      "-----------------------------------------------\n",
      "Training epoch :  339\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065036\n",
      "iter  50:\t Loss = 0.070273\n",
      "iter 100:\t Loss = 0.035240\n",
      "iter 150:\t Loss = 0.061524\n",
      "iter 200:\t Loss = 0.059182\n",
      "iter 250:\t Loss = 0.052289\n",
      "iter 300:\t Loss = 0.040799\n",
      "-----------------------------------------------\n",
      "Training epoch :  340\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.065003\n",
      "iter  50:\t Loss = 0.070262\n",
      "iter 100:\t Loss = 0.035219\n",
      "iter 150:\t Loss = 0.061524\n",
      "iter 200:\t Loss = 0.059163\n",
      "iter 250:\t Loss = 0.052274\n",
      "iter 300:\t Loss = 0.040788\n",
      "-----------------------------------------------\n",
      "Training epoch :  341\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064970\n",
      "iter  50:\t Loss = 0.070251\n",
      "iter 100:\t Loss = 0.035198\n",
      "iter 150:\t Loss = 0.061525\n",
      "iter 200:\t Loss = 0.059144\n",
      "iter 250:\t Loss = 0.052260\n",
      "iter 300:\t Loss = 0.040777\n",
      "-----------------------------------------------\n",
      "Training epoch :  342\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064938\n",
      "iter  50:\t Loss = 0.070240\n",
      "iter 100:\t Loss = 0.035178\n",
      "iter 150:\t Loss = 0.061525\n",
      "iter 200:\t Loss = 0.059126\n",
      "iter 250:\t Loss = 0.052245\n",
      "iter 300:\t Loss = 0.040766\n",
      "-----------------------------------------------\n",
      "Training epoch :  343\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064906\n",
      "iter  50:\t Loss = 0.070229\n",
      "iter 100:\t Loss = 0.035158\n",
      "iter 150:\t Loss = 0.061526\n",
      "iter 200:\t Loss = 0.059107\n",
      "iter 250:\t Loss = 0.052231\n",
      "iter 300:\t Loss = 0.040755\n",
      "-----------------------------------------------\n",
      "Training epoch :  344\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064874\n",
      "iter  50:\t Loss = 0.070218\n",
      "iter 100:\t Loss = 0.035139\n",
      "iter 150:\t Loss = 0.061527\n",
      "iter 200:\t Loss = 0.059089\n",
      "iter 250:\t Loss = 0.052216\n",
      "iter 300:\t Loss = 0.040745\n",
      "-----------------------------------------------\n",
      "Training epoch :  345\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064843\n",
      "iter  50:\t Loss = 0.070208\n",
      "iter 100:\t Loss = 0.035119\n",
      "iter 150:\t Loss = 0.061527\n",
      "iter 200:\t Loss = 0.059071\n",
      "iter 250:\t Loss = 0.052202\n",
      "iter 300:\t Loss = 0.040734\n",
      "-----------------------------------------------\n",
      "Training epoch :  346\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064811\n",
      "iter  50:\t Loss = 0.070198\n",
      "iter 100:\t Loss = 0.035100\n",
      "iter 150:\t Loss = 0.061528\n",
      "iter 200:\t Loss = 0.059053\n",
      "iter 250:\t Loss = 0.052188\n",
      "iter 300:\t Loss = 0.040724\n",
      "-----------------------------------------------\n",
      "Training epoch :  347\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064780\n",
      "iter  50:\t Loss = 0.070188\n",
      "iter 100:\t Loss = 0.035081\n",
      "iter 150:\t Loss = 0.061529\n",
      "iter 200:\t Loss = 0.059035\n",
      "iter 250:\t Loss = 0.052174\n",
      "iter 300:\t Loss = 0.040714\n",
      "-----------------------------------------------\n",
      "Training epoch :  348\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064749\n",
      "iter  50:\t Loss = 0.070179\n",
      "iter 100:\t Loss = 0.035063\n",
      "iter 150:\t Loss = 0.061530\n",
      "iter 200:\t Loss = 0.059018\n",
      "iter 250:\t Loss = 0.052160\n",
      "iter 300:\t Loss = 0.040704\n",
      "-----------------------------------------------\n",
      "Training epoch :  349\n",
      "-----------------------------------------------\n",
      "iter   0:\t Loss = 0.064719\n",
      "iter  50:\t Loss = 0.070169\n",
      "iter 100:\t Loss = 0.035044\n",
      "iter 150:\t Loss = 0.061531\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-626859644531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfeed_dict_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mg_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdisplay_freq\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initializing all variables\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "num_tr_iter=int(len(y_train)/batch_size)\n",
    "print('num_tr_iter = ', num_tr_iter)\n",
    "store_loss_train_name='global_loss_train.dat'\n",
    "sltn=open(store_loss_train_name,\"w+\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('-----------------------------------------------')\n",
    "    print('Training epoch : ', epoch)\n",
    "    print('-----------------------------------------------')\n",
    "    for iteration in range(num_tr_iter):\n",
    "        start=iteration*batch_size\n",
    "        end=(iteration+1)*batch_size\n",
    "        x_batch,dx_batch,z_batch,g_batch,y_batch=get_next_batch(x_train,y_train,start,end)\n",
    "        z_batch=np.expand_dims(z_batch,1)\n",
    "        dx_batch=np.expand_dims(dx_batch,1)\n",
    "        g_batch=np.expand_dims(g_batch,1)\n",
    "        y_batch=np.expand_dims(y_batch,1)\n",
    "\n",
    "        feed_dict_batch={x:x_batch,dx:dx_batch,g:g_batch,z:z_batch,y:y_batch}\n",
    "\n",
    "        sess.run(optimizer,feed_dict=feed_dict_batch)\n",
    "\n",
    "        if iteration%display_freq==0:\n",
    "            loss_batch=sess.run(loss,feed_dict=feed_dict_batch)\n",
    "            print(\"iter {0:3d}:\\t Loss = {1:2f}\".format(iteration,loss_batch))\n",
    "            sltn.write(\"%6d    %15.12f\\n\" %(iteration+epoch*num_tr_iter, loss_batch))\n",
    "sltn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training loss function\n",
    "#matplotlib.figure.Figure()\n",
    "xloss,yloss=np.loadtxt(store_loss_train_name,unpack=True)\n",
    "plt.plot(xloss, yloss)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# save and plot y_predict_train, y_train\n",
    "store_y_train_name='y_train.dat'\n",
    "sytn=open(store_y_train_name,\"w+\")\n",
    "np.random.seed(68721)\n",
    "random_list=np.random.randint(len(y_train),size=2000)\n",
    "x_batch=np.zeros([1000,x_train.shape[1]-3])\n",
    "g_batch=np.zeros([1000,1])\n",
    "dx_batch=np.zeros([1000,1])\n",
    "z_batch=np.zeros([1000,1])\n",
    "y_batch=np.zeros([1000,1])\n",
    "for i in range(1000):\n",
    "    x_batch[i,0:x_train.shape[1]-3]=x_train[random_list[i],0:x_train.shape[1]-3].T\n",
    "    g_batch[i,0]=x_train[random_list[i],x_train.shape[1]-1]\n",
    "    z_batch[i,0]=x_train[random_list[i],x_train.shape[1]-2]\n",
    "    dx_batch[i,0]=x_train[random_list[i],x_train.shape[1]-3]\n",
    "    y_batch[i,0]=y_train[random_list[i]]\n",
    "\n",
    "feed_dict_batch={x:x_batch,dx:dx_batch,g:g_batch,z:z_batch,y:y_batch}\n",
    "y_train_predict=sess.run(output,feed_dict=feed_dict_batch)\n",
    "print(y_train_predict.shape)\n",
    "for i in range(1000):\n",
    "    sytn.write(\"%15.12f    %15.12f\\n\" %(y_batch[i,0], y_train_predict[i,0]))\n",
    "sytn.close()\n",
    "\n",
    "#matplotlib.figure.Figure()\n",
    "y1, y2=np.loadtxt(store_y_train_name,unpack=True)\n",
    "plt.plot(y1, y2,'ro')\n",
    "plt.plot(y1,y1,'-b')\n",
    "plt.xlabel('Y Value')\n",
    "plt.ylabel('Y Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
